{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MB-Fit Documentation (v1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the last decades, the branch of computational chemistry has played an important role in the study of energetic, dynamical and structural properties of chemical and physical processes such as vibrational spectra, phase diagrams, isomerization processes, chemical reactions... Computational chemistry provides a powerful tool to gain insights on the driving forces of these processes under the assumption that the energies, or more accurately, the energy differences, are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When exploring the potential energy surface (PES), there are several computational methods available. *Ab initio* methods provide an accurate solution, depending on the method itself and the basis set used, but the treatable system size is usually small, from a few atoms when using coupled-cluster theory, to a few hundreds of atoms when using density functional theory (DFT). These methods solve the Schrodinger Equation\n",
    "\n",
    "$$\\hat{H}\\Psi = E\\Psi$$\n",
    "\n",
    "for wavefunction methods such as Hartree-Fock, perturbation theory, or coupled-cluster, or the Kohn-Sham equations\n",
    "\n",
    "$$\\left( -\\frac{\\hbar ^2}{2m} \\nabla ^2 + v_{eff}(\\vec{r})\\right) = \\varepsilon _i \\varphi _i (\\vec{r})$$\n",
    "\n",
    "$$\\rho(\\vec{r}) = \\sum _i ^N \\left\\lvert\\varphi _i (\\vec{r}) \\right\\rvert ^2 \\label{eq:dens}$$\n",
    "\n",
    "in the case of DFT. Commonly, systems of interest can have thousands of atoms, and exploring the PES with *ab initio* methods is virtually impossible nowadays. However, one can go to the force field (FF) realm to find very simplified potential energy functions (PEFs) typically based on harmonic potentials for bonded interactions, Lennard-Jones potentials for non-bonded interactions, and point-charge electrostatic interactions. \n",
    "\n",
    "$$ $$\n",
    "\n",
    "These PEFs enable the treatment of tens of thousands of atoms, and can be further simplified by coarse-graining them to reach hundreds of thousands of atoms. However, the accuracy of FFs is not great. We can plot these different methods in a plot of size vs. accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_methods.png\" alt=\"plotmethods\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would like to be in the predictive representation area: have a great accuracy and be able to treat large system sizes. Several approaches can be taken, and one of them is based on the many-body expansion (MBE) of the energy of a system, which can be decomposed as the sum of the one-body energy, plut the two body energy, plus the three-body energy, and so on, until the n-th body:\n",
    "\n",
    "$$ E_{\\text{N}}(1,\\dots,N) = \\sum_{i=1}^N V^{\\text{1B}}(i) + \\sum_{i<j}^NV^{\\text{2B}}(i,j) \n",
    "\t+ \\sum_{i<j<k}^N V^{\\text{3B}}(i,j,k) + \\dots + V^{\\text{NB}}(1,\\dots,N) $$\n",
    "\n",
    "where $V^{\\text{1B}}(i) = 0$ and $V^{\\text{1B}}(i) = E(i) - E_{\\text{eq}}(i)$ for atomic and molecular monomers, respectively. \n",
    "In the latter case, $V^{\\text{1B}}(i)$ corresponds to the one-body (1B) energy required to deform an individual monomer from its equilibrium geometry, and $V^{\\text{nB}}$ are the $n$-body (nB) energies defined recursively as\n",
    "\n",
    "$$ V^{\\text{nB}}(1,\\dots,n) = E_n(1,\\dots,n) - \\sum_iV^{\\text{1B}}(i) - \\sum_{i<j}V^{\\text{2B}}(i,j) - \\sum_{i<j<\\dots<n-1}V^{\\text{(n-1)B}}(i,j,\\dots,(n-1)) $$\n",
    "\n",
    "Since the MBE converges quickly for non-metallic systems such as CH$_4$ and H$_2$O, it provides a rigorous and efficient framework for the development of full-dimensional PEFs in which each individual term of the MBE can be separately determined from high-level electronic structure calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides with the infrastructure to generate one- and two-body PEFs for small molecules, i.e. molecules that have a maximum bond distance between atoms of 4, such as ethane, carbon dioxide, or the case we will present in this document, ammonia. The different PEFs, functional form and terms will be presented as they appear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3.6+ with libraries numpy, matplotlib, and psycopg2\n",
    "\n",
    "External software: PostgreSQL client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will serve as a template that one can use for other small molecules. The first step to ensure that the MB-Fit library can be imported is to add the path to the MB-Fit library to the Python path. To do so, first define the `MBFIT_HOME` environment variable to point to the folder where `MB-fit` is located, and source the file `sourceme.sh` located inside `MBFIT_HOME`. If this step has not been done before opening the notebook, please copy these lines in a bash terminal and reopen the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "export MBFIT_HOME=\"PATH/TO/MBFIT\"\n",
    "source ${MBFIT_HOME}/mbfit.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two lines of code will enable access to the `mbfit` module from any Python script. Now the library should be imported without any error. \n",
    "\n",
    "**NOTE:** Please do not generate any PEF inside the MB-Fit folder. Create a folder somewhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mbfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-body PEF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between 2013 and 2014, the Paesani lab published a full dimentional many-body PEF for water. MB-pol is based on the many-body expansion of the total energy of a system, and  it uses different expressions for the different many-body terms. The one-body term was borrowed from the PEF developed by Partridge and Schwenke. This surface is fitted to reproduce energies from ab initio data, experimental rotational constants, vibrational spectra, and other properties. I was shown to be an excellent model to describe the behavior of an isolated water molecule. From now on, when we talk about MB-pol, $V^{\\text{1B}} = V^{\\text{1B}}_{\\text{PS}}$\n",
    "\n",
    "The one-body energy is also known as the distorion energy, and is typically described by force fields using harmonic fucntions for bonds and angles, and other simple functional forms for dihedrals and inversion angles. Within the MB-nrg framework, the distortion energy will be described with PIPs. The goal of this section is to obtain $V^{\\text{1B}}(\\vec{r})$.\n",
    "\n",
    "The functional form that MB-nrg uses is a set of permutationally invariant polynomials that are a function of the internal distances of the atoms in the monomer.\n",
    "\n",
    "$$ V^{\\text{1B}} = \\sum _i A_i P[\\xi _a  \\xi _b \\dots \\xi _n] $$\n",
    "\n",
    "$A_i$ is a linear constant, and P is a set of permutations that make the system permutationally invariant with respect to the variables $\\xi _j$ that are present in the element $i$ of the sum. The polynomial variables $\\xi$ are a function of a distance between two atoms $r$, and can have different functional forms with the condition that they must decay to 0 when $r \\rightarrow \\infty$. Examples of possible acceptable variable functional forms are Morse type variables ($\\xi(r) = e^{-kr}$) or Coulomb type variables ($\\xi(r) = e^{-kr}/r$)\n",
    "\n",
    "This next part of this text will show how to generate the necessary data to obtain these linear ($A_i$) and non-linear ($k_j$) parameters that allow the best description of the reference PES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electronic structure calculation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MB-Fit supports two different software packages to perform calculations: `QChem` and `Psi4`. There is no difference in using one or the other in terms of obtaining the PEF. For this example we will use `Qchem`, along with the DFT functional $\\omega$B97M-V and the aug-cc-pvtz basis set. All this information will be stored in variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electronic structure software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The options for the package are `\"qchem\"` to use QChem, and `\"psi4\"` to use Psi4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"qchem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electronic structure method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The options here are any method that the ES software can handle. The most common methods to use are any supported DFT functional and coupled-cluster theory (CCSD(T)):\n",
    "```\n",
    "method = \"HF\"     # will use Hartree-Fock\n",
    "method = \"MP2\"    # will use the Moller-Plesset perturbation theory of order 2\n",
    "method = \"PBE0\"   # will use the DFT functional PBE0\n",
    "```\n",
    "In this example we will use $\\omega$B97M-V. This hybrid functional has been shown to have coupled-cluster accuracy for one- and two-body interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"wb97m-v\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basis set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the basis set will determine how reliable are the calculated energies. A larger basis set will be closer to the limit of the level of theory used, but it will be also more computationally expensive. For DFT, aug-cc-pvtz is close to the complete basis set limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = \"aug-cc-pvtz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation details and extra options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, an electronic structure package needs to have the memory and the number of threads that will be used. This can be specified with the variables `num_threads` and `memory`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of threads to use\n",
    "num_threads = 2\n",
    "\n",
    "# Amount of memory to use\n",
    "memory = \"4GB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A part from the basic optiones defined above, sometimes it is needed to define extra variables or parameters in the electronic structure calculation, such as number of SCF iterations, number of geometry optimization steps, energy thresholds... These options can be passed as a dictionary to the corresponding calculations. Each option has a keyword in the corresponding electronic structure software. For example, in QCHEM, to increase the number of SCF iterations, we need to define the keyword `MAX_SCF_CYCLES`, and to increase the maximum number of optimization steps, the keyword `GEOM_OPT_MAX_CYCLES`. We can add these options into a dictionarythat we will then pass to the calculation routines:\n",
    "```\n",
    "qm_options = {\"MAX_SCF_CYCLES\" : 100, \"GEOM_OPT_MAX_CYCLES\" : 80}\n",
    "```\n",
    "which would be equivalent to do:\n",
    "```\n",
    "qm_options[\"MAX_SCF_CYCLES\"] = 100\n",
    "qm_options[\"GEOM_OPT_MAX_CYCLES\"] = 80\n",
    "```\n",
    "In general, no matter the electronic structure code that is being used, the procedure to add extra options to the input is the same: `qm_options[\"option\"] = value`. To see the list of possible `options`, look at the documentation of the corresponding electronic structure code. In our case, we will use the following options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qchem_qm_options = {}\n",
    "qchem_qm_options[\"purecart\"] = \"1111\"\n",
    "qchem_qm_options[\"xc_grid\"] = \"000099000590\"\n",
    "qchem_qm_options[\"nl_grid\"] = \"1\"\n",
    "qchem_qm_options[\"unrestricted\"] = \"false\"\n",
    "qchem_qm_options[\"incdft\"] = \"0\"\n",
    "qchem_qm_options[\"incfock\"] = \"0\"\n",
    "qchem_qm_options[\"max_scf_cycles\"] = \"100\"\n",
    "qchem_qm_options[\"scf_guess\"] = \"sad\"\n",
    "qchem_qm_options[\"scf_convergence\"] = \"6\"\n",
    "qchem_qm_options[\"thresh\"] = \"11\"\n",
    "qchem_qm_options[\"symmetry\"] = \"false\" \n",
    "qchem_qm_options[\"sym_ignore\"] = \"true\"\n",
    "qchem_qm_options[\"geom_opt_max_cycles\"] = 80\n",
    "\n",
    "psi4_qm_options = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MB-Fit needs to know about the system we are dealing with, and the calculation details specified earlier. All this information is stored in a file with all these settings. For convenience, we generate this file *in situ*, and we describe below each one of the components that this file requires. We will refer to this file as `settings` file from now on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the different monomers present in the system is used to identify a given monomer in the database. They have no other purpose rather than identification. The name can have any length, and combine numbers and letters. It is not required but it is recommended to use capital letters only. The `names` variable is a list of strings that contains the monomers in the system:\n",
    "```\n",
    "names = [\"MON1\",\"MON2\",...]\n",
    "```\n",
    "After the definition of this list, the order of the monomers is set. If one has more than one monomer in that list, **monomer 1** will be the first element of the list, **monomer 2** the second one, and so on. When defining the properties of each monomer, this order will be important. In this first example it doesn't matter because there is only one monomer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"NH3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of atoms, spin, and charge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of atoms, charge of each monomer, and spin multiplicity of each monomer will be defined in the lists `number_of_atoms`, `charges`, and `spin`, respectively. These lists are lists of integers, and each element corresponds to the value of the list property of the monomer in that position (as defined in the list `names`.\n",
    "\n",
    "- `number_of_atoms` is the total number of atoms of the monomers. For example, CO$_2$ has 3 atoms, and NH$_3$ has 4. Any virtual site (either for the polynomials or for the electrostatics) should not be counted as \"atom\".\n",
    "- `charges` is the total charge of every monomer. Neutral monomers will have a charge of 0, while ions such as Cl$^-$ or NH$_4^+$ will have a charge of -1 and 1 respectively.\n",
    "- `spin` contains the spin multiplicities of the monomers, calculated as $M = 2S + 1$. For now, only closed shell systems are recommended since they have been throughly tested.\n",
    "\n",
    "If there is only one monomer, these variables still need to be a list, with a single element, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of atoms of each monomer\n",
    "number_of_atoms = [4]\n",
    "\n",
    "# Charge of each monomer\n",
    "charges = [0]\n",
    "\n",
    "# Spin multiplicity of each monomer\n",
    "spin = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use MB-pol for monomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, MB-nrg and TTM-nrg are compatible with MB-pol by construction. When developing a two-body surface for a dimer in which one of the monomers is water, the partridge-shwenke dipole moment PEF should be used to describe the electrostatic properties of water in order to enable full compatibility with MB-pol. This can be passed to the MB-Fit library through the variable `use_mbpol`. If the value of this variable at the position `i` is 1, the monomer `i` will be assumed to be water, and the charges, polarizabilities, and polarizability factors will be calculated using the PS PEF. In this example, we just have ammonia, which is not water, and consequently, the variable `use_mbpol` will be a list of one element set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mbpol = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly, in force fields, the interactions are described in a pairwise way and the different constants of the function describing an interaction depends on the atom types involved. The symmetry keyowrd in `MB-Fit` refers to the label that the atoms have. Each chemically unique atom will have a letter assigned, not related to their chemical identity. In order to build the symmetry, these are the steps to follow:\n",
    "1. Write the empirical formula of your molecule. As an example, for ammonia, is `NH3`\n",
    "2. Expand the chemical formula. This means that if there are two or more atoms that have a subindex, just repeat that atom. In the case of ammonia, we write `NHHH`\n",
    "3. Identify which atoms are chemically equivalent. This is very simple in small molecules, but can be complciated in larger molecules. To figure this out:\n",
    "   1. Locate two atoms that have the same atomic symbol. Two atoms that have different atomic symbols cannot be equivalent.\n",
    "   2. Replace one atom by `X` and look at the molecule.\n",
    "   3. Replace the other atom by `X` and compare this structure with the previous one. If the structure is the same, the two atoms are equivalent.\n",
    "4. Replace all the atomic symbols by letters, starting from `A`, and moving up in the alphabet (`B`,`C`...) using all capital letters. Each unique atom type must be represented by a different letter. In the case of ammonia, `NHHH` will become `ABBB`\n",
    "5. Compress the new label. There must be a number after each type, even if it is `1`. In the case of ammonia will be `A1B3`\n",
    "\n",
    "Then, the symmetry list can be defined as in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry = [\"A1B3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once symmetry is defined, the molecule symmetry can be obtained by joining all the elements in the symmetry list with an underscore `_`. We will refer to it as `molecule_in`. In the case of 1B, symmetry and molecule in will be the same, with the exception that molecule in is a string and not a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_in_nh3 = \"_\".join(symmetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMILES string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMILES string is the way the connectivity of the molecule is passed into `MB-Fit`. In classical force fileds, the interactions between atoms are usually divided in bonded and non-bonded interactions. Typically, two atoms will be bonded if there are three or less bonds of distance between those two atoms, and non-bonded otherwise. When two atoms within the same molecule are non-bonded, the non-bonded interactions such as repulsion, dispersion and electrostatics are calculated, and ignored or scaled if the two atoms are bonded. The SMILES string will allow `MB-Fit` to find the connectivity matrix of the molecule.\n",
    "\n",
    "The SMILES string for each fragment must follow the [general rules](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system#Description) of SMILES strings in addition to the following extra rules:\n",
    "* Order of atoms in the SMILES string must be consistent with the order of the atoms in the symmetry and other inputs, like XYZ files.\n",
    "* All hydrogen atoms must be included explicity.\n",
    "* Do not include any information about charges in your SMILES string.\n",
    "\n",
    "Writting a SMILES string by scratch might seem complicated, but these steps show how to do it in a simple way.\n",
    "1. Write out all atoms of the fragment in the same order they appear in your XYZ file. Remember, if any atom name is 2 letters, you must put square brackets around it.\n",
    "2. Add a '.' between any atoms that are not bonded.\n",
    "3. Add numbers after atoms to signify bonds between non-adjacent atoms. In the SMILES format you can bond two non-adjacent atoms by putting the same digit after them. For example, the SMILES string 'C1CC1' specifies a ring of 3 carbons. When there are multiple digits after a single atom each digit is treated independently. For instance, 'C12.C23.C31' also specifies a ring of 3 carbons. In this representation we have removed the implicit bond between adjacent atoms by adding a dot, and then introduced bonds between each pair of carbon atoms. If you need to specify more than 10 bonds you can use % signs to combine multiple digits: 'C%10%20.C%20%30.C%30%10' also specifies a ring of 3 carbons.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "Lets say our '.xyz' file for formaldehyde looks like this:\n",
    "```\n",
    "4\n",
    "comment line\n",
    "C   x   y   z\n",
    "O   x   y   z\n",
    "H   x   y   z\n",
    "H   x   y   z\n",
    "```\n",
    "\n",
    "Step 1) COHH\n",
    "Step 2) CO.H.H\n",
    "Step 3) C12O.H1.H2\n",
    "\n",
    "Here is another example:\n",
    "```\n",
    "3\n",
    "Chloroform\n",
    "C   x   y   z\n",
    "H   x   y   z\n",
    "Cl  x   y   z\n",
    "Cl  x   y   z\n",
    "Cl  x   y   z\n",
    "```\n",
    "\n",
    "Step 1) CH[Cl][Cl][Cl]\n",
    "Step 2) CH.[Cl].[Cl].[Cl]\n",
    "Step 3) C123H.[Cl]1.[Cl]2.[Cl]3\n",
    "\n",
    "In the case of ammonia, assuming that the XYZ is:\n",
    "```\n",
    "4\n",
    "comment line\n",
    "N   x   y   z\n",
    "H   x   y   z\n",
    "H   x   y   z\n",
    "H   x   y   z\n",
    "```\n",
    "\n",
    "Step 1) NHHH\n",
    "Step 2) NH.H.H\n",
    "Step 3) N12H.H1.H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = [\"N12H.H1.H2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electronic structure outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the electronic structure calculations outputs will be stored. The path where they will be put is defined in `log_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SETTINGS file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties of the system, along with with some of the details for the electronic structure calculations, are stored in the `settings` file. This file is passed to the different methods in `MB-Fit` so the code can retrieve the information of the system. Below is an example of the  settings file. Any line that starts with `#` will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[files]\n",
    "# Local path directory to write log files in\n",
    "log_path = logs\n",
    "\n",
    "[config_generator]\n",
    "# what library to use for geometry optimization and normal mode generation\n",
    "code = psi4\n",
    "# use geometric or linear progression for T and A in config generation, exactly 1 must be True\n",
    "geometric = False\n",
    "linear = False\n",
    "\n",
    "[energy_calculator]\n",
    "# what library to use for energy calculations\n",
    "code = psi4\n",
    "\n",
    "[psi4]\n",
    "# memory to use when doing a psi4 calculation\n",
    "memory = 4GB\n",
    "# number of threads to use when executing a psi4 calculation\n",
    "num_threads = 2\n",
    "\n",
    "[qchem]\n",
    "# number of threads to use when executing a qchem calculation\n",
    "num_threads = 2\n",
    "\n",
    "[molecule]\n",
    "# name of fragments, seperated by commas\n",
    "names = NH3\n",
    "# number of atoms in each fragment, seperated by commas\n",
    "fragments = 4\n",
    "# charge of each fragment, seperated by commas\n",
    "charges = 0\n",
    "# spin multiplicity of each fragment, seperated by commas\n",
    "spins = 1\n",
    "# tag when putting geometries into database\n",
    "tag = none\n",
    "# Use or not MB-pol\n",
    "use_mbpol = 0\n",
    "# symmetry of each fragment, seperated by commas\n",
    "symmetry = A1B3\n",
    "SMILES = N12H.H1.H2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can write the file manually, or can use the following code to write the file with all the information inputed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe29c57ce623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# symmetry of each fragment, seperated by commas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0msymmetry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\" + symmetry[0] + \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mSMILES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\" + smiles[0] + \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Settings for monomer\n",
    "settings_nh3 = \"settings_nh3_monomer.ini\"\n",
    "\n",
    "my_settings_file = \"\"\"\n",
    "[files]\n",
    "# Local path directory to write log files in\n",
    "log_path = \"\"\" + log_path + \"\"\"\n",
    "\n",
    "[config_generator]\n",
    "# what library to use for geometry optimization and normal mode generation\n",
    "code = \"\"\" + code + \"\"\"\n",
    "# use geometric or linear progression for T and A in config generation, exactly 1 must be True\n",
    "geometric = False\n",
    "linear = False\n",
    "\n",
    "[energy_calculator]\n",
    "# what library to use for energy calculations\n",
    "code = \"\"\" + code + \"\"\"\n",
    "\n",
    "[psi4]\n",
    "# memory to use when doing a psi4 calculation\n",
    "memory = \"\"\" + memory + \"\"\"\n",
    "# number of threads to use when executing a psi4 calculation\n",
    "num_threads = \"\"\" + str(num_threads) + \"\"\"\n",
    "\n",
    "[qchem]\n",
    "# number of threads to use when executing a qchem calculation\n",
    "num_threads = \"\"\" + str(num_threads) + \"\"\"\n",
    "\n",
    "[molecule]\n",
    "# name of fragments, seperated by commas\n",
    "names = \"\"\" + names[0] + \"\"\"\n",
    "# number of atoms in each fragment, seperated by commas\n",
    "fragments = \"\"\" + str(number_of_atoms[0]) + \"\"\"\n",
    "# charge of each fragment, seperated by commas\n",
    "charges = \"\"\" + str(charges[0]) + \"\"\"\n",
    "# spin multiplicity of each fragment, seperated by commas\n",
    "spins = \"\"\" + str(spin[0]) + \"\"\"\n",
    "# tag when putting geometries into database\n",
    "tag = none\n",
    "# Use or not MB-pol\n",
    "use_mbpol = \"\"\" + str(use_mbpol[0]) + \"\"\"\n",
    "# symmetry of each fragment, seperated by commas\n",
    "symmetry = \"\"\" + symmetry[0] + \"\"\"\n",
    "SMILES = \"\"\" + smiles[0] + \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file:\n",
    "ff = open(settings_nh3,'w')\n",
    "ff.write(my_settings_file)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The permutationally invariant polynomials can be generated using `MB-Fit`. The first step is to define all the variables that will be involved in the polynomials. They can be obtained by calling the `generate_poly_input` function, which usage is the following, and it generates a file that lists all the different variables that can be in the polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_poly_input(settings_path, molecule_in, in_file_path, virtual_sites=['X', 'Y', 'Z'])\n",
    "    Generates an input file for polynomial generation.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        molecule_in         - String idicating symmetry of molecule, ie \"A1B2_A1B2\" for (CO2)2\n",
    "        in_file_path        - Local path to the file to write the polynomial input to.\n",
    "        virtual_sites       - List of Symmetry labels that are virtual sites.\n",
    "                Default: [\"X\", \"Y\", \"Z\"]\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function requires the settings file, previously defined and explained. It also requires the molecule symmetry, which as mentioned earlier, has been defined in `molecule_in`. The argument `in_file_path` will contain the name of the file that will be generated with all the information. The optional argument `virtual_sites` specifies which letters will represent virtual sites in the molecules. Currently, `MB-fit` only accepts virtual sites for `MB-pol` water, and will be described later in the manual. Before generating the polynomial input file, let's define the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_in_nh3 = \"poly_nh3.in\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the polynomial generation input with all the variables can be generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mbfit.generate_poly_input(settings_nh3, molecule_in_nh3, poly_in_nh3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file generated should be like this:\n",
    "```\n",
    "add_molecule['A1B3']\n",
    "\n",
    "add_variable['A', '1', 'a', 'B', '1', 'a', 'x-intra-A+B-1']\n",
    "add_variable['A', '1', 'a', 'B', '2', 'a', 'x-intra-A+B-1']\n",
    "add_variable['A', '1', 'a', 'B', '3', 'a', 'x-intra-A+B-1']\n",
    "add_variable['B', '1', 'a', 'B', '2', 'a', 'x-intra-B+B-1']\n",
    "add_variable['B', '1', 'a', 'B', '3', 'a', 'x-intra-B+B-1']\n",
    "add_variable['B', '2', 'a', 'B', '3', 'a', 'x-intra-B+B-1']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two keywords in the generated file. The first one, `add_molecule` states that a new molecule is added to the system. The second one, `add_variable`, specifies that a variable $\\xi _{ij}$ that depends on the distance between atoms $i$ and $j$ will be added to the system. Concretely,\n",
    "```\n",
    "add_variable['A', '1', 'a', 'B', '2', 'a', 'x-intra-A+B-1']\n",
    "```\n",
    "translates into add a variable between the first atom of type `A` from the first monomer (`a`) `['A', '1', 'a']` and the second atom of type `B` of the first monomer (`a`) `['B', '2', 'a']`, which non-linear parameter constant will have the tag `x-intra-A+B-1`. Variables with the same constant tag will have the same non-linear parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user is free to remove any variable that is not wanted in the polynomial expression, but the use of all the variables and the addition of filters is the recommended option. When the molecule grows in size and the polynomial maximum order increases, the number of terms that the polynomial has increases exponentially. Typically, the number of terms in the polynomial should not exceed 2000, and this number is easily exceeded for larger systems. In these situations, the best solution is to apply filters. An extended explanation of the filter format and their options can be found in the `FILTERS.md` file inside `MBFIT_HOME/docs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the input and the filters have been decided, the polynomial generation function `generate_polynomials` can be called:\n",
    "```\n",
    "generate_polynomials(settings_path, poly_in_path, order, poly_dir_path, generate_direct_gradients=True, num_gradient_terms_per_line=1)\n",
    "    Generates polynomial input for maple and some \".cpp\" and \".h\" polynomial files.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        poly_in_path        - Local path to the file to read the polynomial input from. Name of file should be in\n",
    "                the format \"A1B2.in\". It is ok to have extra directories prior to file name. For example:\n",
    "                \"thisplace/thatplace/A3.in\".\n",
    "        order               - The order of the polynomial to generate.\n",
    "        poly_dir_path       - Local path to the directory to write the polynomial files in.\n",
    "        generate_direct_gradients - If True, then a gradients cpp file is generate additionally to the polynomial\n",
    "                cpp file. This may take a while.\n",
    "                defualt: False.\n",
    "        num_gradient_terms_per_line - The number of terms to put in each line in the cpp file\n",
    "                for computing the gradients. Larger numbers may result in slower compilation times.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`settings_path` is the settings file. Since it was generated in the working directory, the name of the file will be enough, and has been defined earlier under the variable `settings_nh3`; same with the `poly_in_path`. The maximum order that the polynomial will have is set by `order`. Given a triatomic molecule `B--A--B`, there are three distances: between atoms A and B$_1$, which we call $\\vec{r}_{AB_1}$; between atoms A and B$_2$ ($\\vec{r}_{AB_2}$); and between atoms B$_1$ and B$_2$ ($\\vec{r}_{B_1B_2}$). Consequently, there are three possible variables that can be used to generate the polynomials: $\\xi _{AB_1}$, $\\xi _{AB_2}$, and $\\xi _{B_1B_2}$. Note that at this point the functional form of $\\xi$ is still irrelevant, but it is a function of the distance between the two atoms involved. With these three variables the following polynomial can be written:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\xi _{AB_1},\\xi _{AB_2},\\xi _{B_1B_2}) &=  K_1\\xi _{AB_1} + K_2\\xi _{AB_2} + K_3\\xi _{B_1B_2} \\leftarrow \\text{Degree 1} \\\\\n",
    "&+ K_4\\xi _{AB_1}\\xi _{AB_1} + K_5\\xi _{AB_2}\\xi _{AB_2} + K_6\\xi _{B_1B_2}\\xi _{B_1B_2} + K_7\\xi _{AB_1}\\xi _{AB_2} + K_8\\xi _{AB_1}\\xi _{B_1B_2} + K_9\\xi _{AB_2}\\xi _{B_1B_2} \\leftarrow \\text{Degree 2} \\\\\n",
    "&+ K_{10}\\xi _{AB_1}\\xi _{AB_1}\\xi _{AB_1} + ... \\leftarrow \\text{Degree 3}\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(\\xi _{AB_1},\\xi _{AB_2},\\xi _{B_1B_2})$ can be written up to any degree, but the higher the degree, the higher the number of terms. For a given molecule, several orders should be tested and use a maximum polynomial degree $n$ that keeps the number of linear terms $K_i\\xi_1 ^{a_1} ... \\xi _k ^{a_k}$, with $\\sum _{j=1} ^ k a_j \\leq n$, lower than 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_order_nh3 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been talking about permutationally invariant polynomials, but the polynomial above is not permutationally invariant. Specifically, let's look at the first degree terms $K_1\\xi _{AB_1}$ and $K_2\\xi _{AB_2}$. $\\xi _{AB_1}$ refers to the distance between A and the **first** B atom, while $\\xi _{AB_2}$ refers to the distance between A and the **second** B atom. However, both variables $\\xi _{AB_1}$ and $\\xi _{AB_2}$ should have the same constant parameters since both are describing the same exact distance type. If the constants $K_1$ and $K_2$ are different, changing the order of the B atoms would change the value of the polynomial evaluation, and physically, this is not correct, since no matter which order the B atoms have, the molecule AB2 is exactly the same. The symmetrization process, which is also performed in the generation of the polynomials, fixes this issue. Instead of having two terms $K_1\\xi _{AB_1}$ and $K_2\\xi _{AB_2}$, the algorithm will symetrize them into $K_{\\alpha}(\\xi _{AB_1} + \\xi _{AB_2})$. With this new term it doesnt matter which atom B is B$_1$ or B$_2$, and it will always evaluate to the same value no matter the order of identical atoms. This process is performed for all the terms that can be symmetrized, reducing the number of linear constants $K$ that will need to be fitted, and ensuring the permutationally invariance of the polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_polynomials` function can aso generate the analytical gradients of the polynomials. However, for fitting purposes, the gradients are not used. These files will be required by `MBX` in order to run molecular dynamics simulations or other calculations that require the gradients. If thegradients are generated, depending on the size of the molecule and the degree, each one of the variable gradients can have hundreds or thousands of terms. Compilation time in these situations becomes extremely slow, and can be improved with a payback on the runtime speed by splitting the calculation of each variable gradient. The number of terms per group is controlled by the `num_gradient_terms_per_line` argument. All the polynomial files will be generated and added to the folder defined in `poly_in_path`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_directory_nh3 = \"polynomials_files_directory_nh3_monomer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_polynomials(settings_nh3, poly_in_nh3, polynomial_order_nh3, polynomial_directory_nh3, \n",
    "                           generate_direct_gradients=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several files should have been generated in the folder `polynomial_directory_nh3`:\n",
    "- `poly.log` contains the information about how many variables, permutations, and terms for each degree the polynomial has, including the total number of terms and the filtered terms. The total number of terms at the end of that file is the number of $K_i\\xi_1 ^{a_1} ... \\xi _k ^{a_k}$ terms that the polynomial will have. If this number is larger than 2000, some filtering should be added, or the maximum degree should be decreased. Physical intuition should be used when adding filters. As an example, if a given degree $n$ yields too many terms, filtering the terms that contain a high degree of a variable involving two atoms which interaction is very small, such as two hydrogen atoms, is a good strategy. This reduces the number of terms and maintains the flexibility of the polynomial.\n",
    "- `vars.cpp` is a file that summarizes the variables involved in the polynomial. This file is not used by the user and contains the same information as the polynomial input file.\n",
    "- `poly-direct.cpp` is a C++ function that given the linear coefficients $K_i$ and the variables $\\xi _j$ will return the evaluation of the polynomial at that point. A `poly-direct-grd.cpp` file will be generated if the gradients have been calculated. This file will return the same value as the `poly-direct.cpp` file in addition to the gradients of each one of the derivatives. Summarizing, given $\\vec{K} = [K_1, K_2, ..., K_M]$ and $\\vec{\\xi} = [\\xi _1,\\xi _2, ..., \\xi _N]$, where $M$ is the number of terms and $N$ is the number of variables, `poly-direct.cpp` will return $V_{poly}$, and `poly-direct-grd.cpp` will return the same $V_{poly}$ and the gradients $\\nabla P(\\xi _1, ... , \\xi _N) = \\lbrack \\frac{\\partial P}{\\xi _1},..., \\frac{\\partial P}{\\xi _N} \\rbrack$. The `poly-model.h` file is the header file for both gradient and no-gradient files.\n",
    "- `poly-nogrd.maple` and  `poly-grd.maple` are MAPLE input files that are automatically generated no matter the options in the polynomials. The polynomial evaluations in the direct form is slow, and if the user has MAPLE, the function `execute_maple` can be used to optimize the evaluation of the polynomials. This step will generate optimized evaluations for the polynomials with and without gradients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "execute_maple(settings_path, poly_dir_path)\n",
    "    Runs maple on the polynomial files in the specified directory to turn them into actual cpp files.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        poly_directory      - Local path to the directory to read the \".maple\" files from and write the \".cpp\" files\n",
    "                to.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two arguments of this function have been previously described, and it will generate two extra useful files to be used for the energy evaluation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.execute_maple(settings_nh3, polynomial_directory_nh3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the previous command has been executed, two extra files conaining the optimized evaluation of the polynomial function with and without gradients have been generated, being `poly-grd.cpp` and `poly-nogrd.cpp` those files. Note that although it is possible to proceed without MAPLE, it is strongly recommended to use it, since the optimized polynomials have around a 4x improvement in evaluation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set and test set generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any machine learning scheme, the goal is to be able to predict the outcome of an event by using knowledge of events in which the outcome is known. In the case of energy, the goal is to predict the energy of a molecular system given the coordinates of all the atoms. We need to train the model with configurations for which the energy is known. These set of configurations will be the **training set**. To assess that the model actually predicts the right energies, we will also need a set of configurations for which the energy is known, but that will not be included in the training set. This set of configurations will be called the **test set**. Usually we will assess the accuracy of a fit by calculating the root mean square deviation (RMSD) of the training and test sets. Ideally, both sets should have a low RMSD and of a similar order of magnitude. To calculate the RMSD, the following expression is used:\n",
    "$$\\text{RMSD} = \\sqrt{\\frac{\\sum _{i=1} ^N (y_i^{calc} - y_i^{ref})^2}{N}}$$\n",
    "where $N$ is the number of data points, $y_i^{calc}$ is the value of the predicted energy, and $y_i^{ref}$ is the reference energy of that same configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree of the polynomial and the size of the training set must be carefully selected to avoid underfitting and overfitting. Underfitting occurs when the function used as model is not flexible enough to reproduce the reference data. An example of underfitting is found on the left panel in the figure below. The model used is a straight line, and it is trying to reproduce a curve with not much success. Although this is a problem in terms of accuracy of the model, it usually does not represent a problem in its stability. However, when the model has too many parameters in comparison with the number of points in the training set (shown on the right), overfitting can occur. The fit will have an apparent excellent agreement with the reference data, but the test set will probably have a bad agreement with the model. When the RMSD of the training set is small, but the one for the test set is large, overfitting is most likely happening and we need to either increase the size of our training set, or decrease the number of terms. When overfitting occurs, there is a big chance of finding **holes** in the PEF, which means that the models does not have information in a region of the space, and the energy that is predicted is usually largely negative, as it is shown in the right pannel of the figure below. Ideally, the wanted behavior is the one shown in the central pannel, in which the model behaves properly within the range of the sample points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/over_underfitting.png\" alt=\"overunderfitting\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend to have a training set with a number of configurations that is 20 times the number of linear terms in the polynomials, with a minimum of 500 configurations, and use a 20% of that number for the test set. We first need to define the names of the training and the test sets. First we will generate the configurations, and then we will generate the formatted training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XYZ file with the configurations of the training set\n",
    "training_configs_nh3 = \"training_configs_nh3.xyz\"\n",
    "\n",
    "# XYZ file with the configurations of the test set\n",
    "test_configs_nh3 = \"test_configs_nh3.xyz\"\n",
    "\n",
    "# XYZ file with the training set that the codes need to perform the fit\n",
    "# Configurations are the same as training_configs but this file\n",
    "# has the energies in the comment line\n",
    "training_set_nh3 = \"training_set_nh3.xyz\"\n",
    "\n",
    "# XYZ file with the test set that the codes need to perform the fit\n",
    "# Configurations are the same as test_configs but this file\n",
    "# has the energies in the comment line \n",
    "test_set_nh3 = \"test_set_nh3.xyz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the definition of the filenames that will contain the training and test configurations and formatted sets, we have to specify the details of the training set. The number of configuration will be the first point to tackle. As mentioned, it should be at least 20 times the number of terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of configurations in the 1b training_set\n",
    "num_training_configs = 500\n",
    "\n",
    "# Number of configurations in the 1b test set\n",
    "num_test_configs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set and the test set must contain configurations around the minimum energy structure (the configuration with the lowest energy). However, distorted configurations must also appear to avoid extrapolationg values for the polynomials. The average energy, following a Boltzman distribution, in a molecular dynamics simulation at room temperature is 0.593 kcal/mol. Technically, having distortions up to 0.6 kcal/mol should be enough to have a stable simulation at room temperature. However, 0.593 kcal/mol is the average energy that a molecule will have, and does not mean that a higher values are not possible. There might be instantaneous fluctuations in which the molecule is distorted several kcal/mol, and if those configurations are not sampled in the training set, the PEF will have a hole, giving a non-physical value for the energy. The recomendation is to use a maximum distortion energy ($E_i ^{dist} = E_i -E_i ^{min}$) of 100 kcal/mol. This will ensure that the configurational space that can be visited up to several hundreds Kelvin is represented in the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum energy allowed for distorted monomers (in kcal/mol)\n",
    "maximum_1b_energy = 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the formatted training set is nothing else than a single XYZ file with all the configurations, one after the other one, with two numbers in the comment line, which are, in this order, the binding energy and the n-body energy. In this first ammonia example, the n-body energy is the one-body energy. The different orders of the many-body energies have been introduced earlier. However, the concept binding energy (BE) appears here for the first time. There are multiple definitions on how to calculate the BE, but the simplest way is:\n",
    "$$ \\text{BE} = E^{tot} - \\sum _{i=1} ^N E_i ^{opt}$$\n",
    "where $E^{tot}$ is the total energy of the system, $N$ is the total number of monomers in the system, and $E_i^{opt}$ is the optimized energy of monomer $i$. If we work out the equation for one-body, we conclude that for this case, the binding energy and the distorsion energy are the same.\n",
    "$$ \\text{BE} = E^{tot} - E_1 ^{opt} = E ^{dist}$$\n",
    "Thus, the maximum binding energy will be set to be the same as the maximum distortion energy (or also one-body energy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_binding_energy = maximum_1b_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set and the test set will both be generated, in the case of the one-body PEF, using normal mode samplig. To do so, the first step is to optimize the molecule and calculate the normal modes. We first need to define a structure that is close the the minimum energy structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XYZ file that contains the unoptimized geommetry of monomer 1\n",
    "unoptimized_nh3 = \"nh3.xyz\"\n",
    "\n",
    "my_unopt_monomer = \"\"\"4\n",
    "unoptimized nh3\n",
    " N                 -0.79953653    0.30706836    0.00000000\n",
    " H                 -0.46621464   -0.63574472    0.00000000\n",
    " H                 -0.46619743    0.77846854    0.81649673\n",
    " H                 -0.46619743    0.77846854   -0.81649673\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file:\n",
    "ff = open(unoptimized_nh3,'w')\n",
    "ff.write(my_unopt_monomer)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XYZ file where the optimized monomer structure will be stored has to be defined too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_nh3 = \"nh3_opt.xyz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to perform the optimization. The function `optimize_geometry` will take care of that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "optimize_geometry(settings_path, unopt_geo_path, opt_geo_path, method, basis, qm_options={})\n",
    "    Optimizes the geometry of the given molecule.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        unopt_geo_path      - Local path to the file to read the unoptimized geoemtry from.\n",
    "        opt_geo_path        - Local path to the file to write the optimized geometry to.\n",
    "        method              - The method to use for this geometry optimization.\n",
    "        basis               - The basis to use for this geometry optimization.\n",
    "        qm_options           - Dictionary of extra arguments to be passed to the QM code doing the calculation.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the arguments of this function have been previously defined. After the call, a new file with the optimized geometry will have appeared in the working directory. This function will use the electronic structure method defined in `method` with the basis set defined in `basis`, to optimize the geometry in the file defined by `unoptimized_nh3`, and save the result in the file defined by `optimized_nh3` using the options defined in `qm_options`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.optimize_geometry(settings_nh3, unoptimized_nh3, optimized_nh3, method, basis, qchem_qm_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the optimized structure has been obtained, it can be used to calculate the normal modes with the `generate_normal_modes` function, which will perform a normal mode calculation using the software, method and basis set specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_normal_modes(settings_path, opt_geo_path, normal_modes_path, method, basis, qm_options={})\n",
    "    Generates the normal modes for the given molecule.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        opt_geo_path        - Local path to the file to read the optimized geometry from.\n",
    "        normal_modes_path   - Local path to the file to write the normal modes to.\n",
    "        method              - The method to use for this normal modes calculation.\n",
    "        basis               - The basis to use for this normal modes calculation.\n",
    "        qm_options           - Dictionary of extra arguments to be passed to the QM code doing the calculation.\n",
    "    \n",
    "    Returns:\n",
    "        Null dimension of normal modes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normals modes will be calculated, and their frequencies and displacement vectors will be stored in the formatted file `normal_modes_path`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_modes_nh3 = \"normal_modes_nh3.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_normal_modes(settings_nh3, optimized_nh3, normal_modes_nh3, method, basis, qchem_qm_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distorted configurations of the monomer are obtained by using the normal mode displacements calculated in the previous step. The normal modes are sampled following a distribution, and depending on the distribution and the sampling method, different sets of configurations that sample different regions of the configurational space will be obtained. The configuration generation is performed by the function `generate_normal_mode_configurations`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_normal_mode_configurations(settings_path, opt_geo_path, normal_modes_path, configurations_path, number_of_configs=100, seed=None, classical=True, distribution='piecewise', temperature=None, distribution_function=None)\n",
    "    Generates normal mode configurations for a given molecule from a set of normal modes.\n",
    "    \n",
    "    If both linear and geometric are False, will use a piecewise distribution over temperature.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        opt_geo_path        - Local path to the file to read optimized geometry from.\n",
    "        normal_modes_path   - Local path to the file to read normal modes from.\n",
    "        TODO Fix this in docs\n",
    "        dim_null            - The null dimension of this molecule, see generate_normal_modes().\n",
    "        config_path         - Local path to the file to write configurations to.\n",
    "        number_of_configs   - Number of configurations to generate\n",
    "        seed                - The same seed with the same molecule and normal modes will always generate the same\n",
    "                configurations.\n",
    "        classical           - If True, use a classical distribution over temp and A, otherwise, use a quantum\n",
    "                distribution. QM distributions generate a wider distribution over energy.\n",
    "                Default: True\n",
    "        distribution        - One of the following choices: 'piecewise', 'constant', 'linear', 'geometric', 'custom'\n",
    "                'piecewise' uses a piecewise distribution in the following style:\n",
    "                    5% at highest frequency / 100\n",
    "                    40% at highest frequency / 20\n",
    "                    30% at highest frequency / 10\n",
    "                    20% at highest frequency / 5\n",
    "                    5% at highest frequency / 2\n",
    "                'constant' uses a set temperature for all configurations.\n",
    "                    Specify the temperature by setting the temperature argument to a single value.\n",
    "                'linear' uses a linear distribution from a minimum to a maximum temperature.\n",
    "                    Specify the min and max temperature by setting the temperature argument to a 2-tuple: (min, max).\n",
    "                    If temperature is unspecified, then the minimum is 0, and the maximum is the highest normal mode frequency.\n",
    "                'geometric' uses a geometric distribution from a minimum to a maximum temperature.\n",
    "                    Specify the min and max temperature by setting the temperature argument to a 2-tuple: (min, max).\n",
    "                    If temperature is unspecified, then the minimum is 0, and the maximum is the highest normal mode frequency.\n",
    "                'custom' uses a user-specified DistributionFunction to generate the temperatures used during configuration generation.\n",
    "        temperature         - Should be set to different values based on what distribution is being used.\n",
    "                If 'piecewise' or 'custom' distribution, then temperature is ignored.\n",
    "                If 'constant' distribution, then temperature should be a single value.\n",
    "                If 'linear' or 'geometric' distribution, then temperature should be a 2-tuple: (min, max)\n",
    "                All temperatures should be specified in KELVIN.\n",
    "        distribution_function - Implementation of DistributionFunction. Only used if distribution='custom'.\n",
    "                distribution_function.get_vale(x) should be implemented over the domain [0,1]. So the first config\n",
    "                will have temperature = distribution_function.get_value(0) and the last config will have temperature =\n",
    "                distribution_function.get_value(1), with configurations in between passing linearly increasing values to \n",
    "                distribution_function.get_value(x).\n",
    "                The distribution_function should return temperatures in atomic units (NOT KELVIN).\n",
    "                See package utils.distribution_function for abstract DistributionFunction class and example implementaitons.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function, some of the arguments have already been seen. The configurations that will be generated are going to be stored in the file defined by `config_path`, previoulsy defined as `training_configs_nh3` and `test_configs_nh3`, and will generate as many configurations as `number_of_configs` indicates. \n",
    "\n",
    "The selection of the normal mode coordinates will be given by random numbers. As in any random number generator, it needs a seed. If no seed is given to the functions that use random numbers, the machine time will be taken as seed, which ensures different results every time that the function is run. The recomendation is to use a defined seed for every function call, to ensure reproducibility of the results. However, the seeds for different sets of the training or test set must be different, or exactly the same configurations will be generated. The seed must be an integer within the python integer range:\n",
    "\n",
    "($2^{31} - 1$,$-(2^{31}) - 2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed_training = 12345\n",
    "seed_test = 54321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can define the temperature (in Kelvin) at which the normal modes will be sampled. If undefined, the piecewise distribution of temperatures will be used. Note that the distribution must be set to `constant` if the normal modes are sampled at a single temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = None # use the piecewise distribution of temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using or not a classical distribution is the user's choice. Classical distributions will result in narrower distributions, but at high temperature of sampling, the classical and the quantum distribution will become more similar. In this example, the classical distribution will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the options have been defined, and the training and test set configurations can be now generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "mbfit.generate_normal_mode_configurations(settings_nh3, optimized_nh3, normal_modes_nh3, \n",
    "                                          training_configs_nh3, number_of_configs=num_training_configs, \n",
    "                                          seed=seed_training, classical=classical)\n",
    "\n",
    "#Test Set\n",
    "mbfit.generate_normal_mode_configurations(settings_nh3, optimized_nh3, normal_modes_nh3, \n",
    "                                          test_configs_nh3, number_of_configs=num_test_configs, \n",
    "                                          seed=seed_test, classical=classical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electronic Structure Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the configurations generated, the next step is to calculate the energy of each one of them. In this example, we will use qchem to perform the calculations. `MB-Fit` provides an infrastructure based on a PostreSQL database to store the results of the calculations. See $MBFIT_HOME/docs/DATABASE_SETUP.txt for instructions on setting up your PostgreSQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maybe add some info about what to do and how to install**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After set up and installation of the database, the information to access it must be written in a file. Any function that performs operations on the database, either writting or reading information, needs a `database.ini` file with the information about the host, the port, the database name, the username, and the password. The format of this file is similar to the `settings` file:\n",
    "\n",
    "```\n",
    "[database]\n",
    "host = host.name.edu\n",
    "port = 5432\n",
    "database = my_database\n",
    "username = my_username\n",
    "password = my_password\n",
    "```\n",
    "\n",
    "The file is created below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_settings = \"database.ini\"\n",
    "my_database_settings = \"\"\"[database]\n",
    "host = host.name.edu\n",
    "port = 5432\n",
    "database = my_database\n",
    "username = my_username\n",
    "password = my_password\n",
    "\"\"\"\n",
    "\n",
    "# Write the file. Remember to update the username and password!\n",
    "ff = open(database_settings,'w')\n",
    "ff.write(my_database_settings)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the database is set up, the configurations generated for the test and for the training set can be added with the function `init_database`. This will add all the configurations of a given XYZ file to the database. If the configuration is already there and it has the same tag, it won't add it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "init_database(settings_path, database_config_path, configurations_path, method, basis, cp, *tags, optimized=False)\n",
    "    Creates a database from the given configuration .xyz files. Can be called on a new database\n",
    "    to create a new database, or an existing database to add more energies to be calculated\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        database_config_path - .ini file containing host, port, database, username, and password.\n",
    "                    Make sure only you have access to this file or your password will be compromised!\n",
    "        configurations_path - Local path to a single .xyz file.\n",
    "        method              - QM method to use to calculate the energy of these configurations.\n",
    "        basis               - QM basis to use to calculate the energy of these configurations.\n",
    "        cp                  - Use counterpoise correction for these configurations?\n",
    "        tags                - Mark the new configurations with these tags.\n",
    "        optimized           - Are these configurations optimized geometries? Defualt is False.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`settings_path` is the path to the settings file as usual, and `database_config_path` is the file that contains the database access information. `configurations_path` is the XYZ file that contains the configuration(s) that need to be added to the database. Each file needs to be added in a different function call. `method` and `basis` are the electronic structure method and basis set that will be used to calculate the energies of the configurations added. When using small basis sets, and even large basis sets that are not close to the complete basis set limit, it is recomended to use counter-poise correction to correct for the basis set superposition error (BSSE). This option can be activated by setting `cp` to `True`. This correction only takes effect if there is more than one monomer, so for the one-body calculations can be set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these mandatory arguments, the `tags` are needed. The function of the tags is to differenciate molecules that are the same but belong to multiple sets. In this simple example, there are two sets that should have excluding geometries, i.e. a geometry in the training set should not be present in the test set and viceversa. Two tags will be used: `\"training_nh3\"` for the training set and `\"test_nh3\"` for the test set. Finally, the `optimized` argument indicates if the configurations added are optimized (the minimum energy structure) or not, and can be set to `True` or `False`. The optimized geommetry must always be in any set, since is used to calculate the binding energy required to generate the formatted training sets. To add the configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add training set configurations\n",
    "mbfit.init_database(settings_nh3, database_settings, training_configs_nh3, method, basis, cp, \"training_nh3\", optimized = False)\n",
    "\n",
    "# Add test set configurations\n",
    "mbfit.init_database(settings_nh3, database_settings, test_configs_nh3, method, basis, cp, \"test_nh3\", optimized = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the optimized monomer to both tags\n",
    "mbfit.init_database(settings_nh3, database_settings, optimized_nh3, method, basis, cp, \"training_nh3\", \"test_nh3\", optimized = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configurations are now in the database ready to be computed. The set of electronic structure calculations can be computed simply by calling the `fill_database` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "fill_database(settings_path, database_config_path, client_name, *tags, calculation_count=9223372036854775807, qm_options={})\n",
    "    Goes through all the uncalculated energies in a database and calculates them. Will take a while. May be interrupted\n",
    "    and restarted.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevant settings information.\n",
    "        database_config_path - .ini file containing host, port, database, username, and password.\n",
    "                    Make sure only you have access to this file or your password will be compromised!\n",
    "        client_name         - Name of the client performing these calculations.\n",
    "        tags                - Only perform calculations marked with at least one of these tags.\n",
    "        calculation_count   - Maximum number of calculations to perform. Unlimited if None.\n",
    "        qm_options           - Dictionary of extra arguments to be passed to the QM code doing the calculation.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will loop over all the jobs in the database associated with the tags passed as arguments, and will run the ones in pending state. The mandatory argument `client_name` is the name of the client using the database. You may put whatever you want here, but we recommend using it to remember who ran the calculations or on which machine they were run. We can call it `TheManual`. The optional argment `calculation_count` specifies the maximum number of calculations that will be run, the default is practically unlimited. All the other arguments have been described in previous calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_name = \"TheManual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.fill_database(settings_nh3, database_settings, client_name, \"training_nh3\", \"test_nh3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option to fill the database with the energies is to use the job maker and the job reader. If a supercomputer is available, it might be convenient to write python scripts that will execute each calculation separately. Then, on the supercomputer one can just loop and submit each job separetly. First, we must use the `make_jobs` function to generate the python scripts. They will be stored in the `jobs_folder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_folder = \"jobs\"\n",
    "mbfit.make_jobs(settings_nh3, database_settings, \n",
    "                            client_name,jobs_folder, \n",
    "                            \"training_nh3\", \"test_nh3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job scripts have been generated, they can be run externally. An example is shown below, but possibilities are limitless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the jobs (can be done externally, supercomputer...)\n",
    "import glob\n",
    "\n",
    "# Check if jobs folder exists\n",
    "if os.path.isdir(jobs_folder):\n",
    "    os.chdir(jobs_folder)\n",
    "    \n",
    "    # Look for all the files that are a python script in that folder\n",
    "    job_files = glob.glob('*.py')\n",
    "    njobs = 0\n",
    "    # Run each job\n",
    "    for this_job in job_files:\n",
    "        njobs += 1\n",
    "        print(njobs,\"/\",len(job_files))\n",
    "        os.system(\"python3 \" + this_job)\n",
    "    os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, after all the jobs have been completed, the call to the `read_jobs` function must be made to add all the information inside the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the job outputs and store information in the database\n",
    "if os.path.isdir(jobs_folder):\n",
    "    mbfit.read_jobs(settings_nh3, database_settings, jobs_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the configurations already in the database, the final step of the training set generation is to create the formatted training and test sets files. The training set and the test set are expected to be in XYZ format with the binding energy and the n-body energy, in this order, in the comment line. Distances are expected to be in Angstrom, and energies in kcal/mol:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<number of atoms>\n",
    "<Binding Energy (kcal/mol)> <N-body Energy (kcal/mol)>\n",
    "At1   At1x   At1y   At1z\n",
    "At2   At2x   At2y   At2z\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set can be automatically generated if the electronic structure calculations have been put in the database. Otherwise, one needs to generate it manually. In order to retrieve it from the database, the function `generate_training_set` must be called:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_training_set(settings_path, database_config_path, training_set_path, method, basis, cp, *tags, e_bind_min=-inf, e_bind_max=inf, e_mon_min=-inf, e_mon_max=inf, deprecated_fitcode=False)\n",
    "    \"\n",
    "    Creates a training set file from the calculated energies in a database.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the \".ini\" file with all relevent settings information.\n",
    "        database_config_path - .ini file containing host, port, database, username, and password.\n",
    "                    Make sure only you have access to this file or your password will be compromised!\n",
    "        training_set_path   - Local path to file to write training set to.\n",
    "        method              - Use energies calculated with this method. Use % for any method.\n",
    "        basis               - Use energies calculated with this basis. Use % for any basis.\n",
    "        cp                  - Use energies calculated with this cp. Use 0 for False, 1 for True, or % for any cp.\n",
    "        tags                - Use energies marked with at least one of these tags. Use % for any tag.\n",
    "        e_bind_min          - Minimum binding energy allowed, inclusive.\n",
    "        e_bind_max          - Maximum binding energy allowed, exclusive.\n",
    "        e_mon_max           - Minimum monomer deformation energy allowed, inclusive.\n",
    "        e_mon_max           - Maximum monomer deformation energy allowed, exclusive.\n",
    "        deprecated_fitcode  - Is this function being called to be used with the deprecated fitcode?\n",
    "                The output of the 1b and 2b training sets will be different.\n",
    "    \n",
    "    Return:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new mandatory argument `training_set_path` is the path to the file where the training set (or test set) will be written. The optional arguments `e_bind_min` and `e_bind_max` are the minimum and maximum binding energy allowed for configuration in the training set. One typically wants to include high energy configurations but no more than 100-150 kcal/mol. Otherwise, although weights are used in the fitting procedure, these configurations might make the low energy region slightly less accurate. The optional arguments `e_mon_min` and `e_mon_max` determine the minimum and maximum distortion energy allowed for a monomer. It is recommended not to have distortions higher than 40 kcal/mol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = \"nh3_monomer_training_set.xyz\"\n",
    "test_set = \"nh3_monomer_test_set.xyz\"\n",
    "e_bind_max = maximum_binding_energy\n",
    "e_mon_max = maximum_1b_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the training set\n",
    "mbfit.generate_training_set(settings_nh3,database_settings,training_set,method,basis,cp,\n",
    "                            \"training_nh3\",e_bind_max = e_bind_max,e_mon_max = e_mon_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the test set\n",
    "mbfit.generate_training_set(settings_nh3,database_settings,test_set,method,basis,cp,\n",
    "                            \"test_nh3\",e_bind_max = e_bind_max,e_mon_max = e_mon_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate system properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total n-body energy of a system can be decomposed in different contributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V^{nb} = V_{poly}^{nb} + V_{rep}^{nb} + V_{disp}^{nb} + V_{elec}^{nb}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $V_{rep}^{nb}$ is the short range (or repulsive) energy, $V_{disp}^{nb}$ is the dispersion energy, $V_{elec}^{nb}$ is the electrostatic energy, and $V_{poly}^{nb}$ is the polynomial correction that we can obtain to reproduce the reference data. Although the previous expression was written in a general form for any n-body system, the repulsion and dispersion terms only appear for large monomers (when there are non-excluded pairs) and dimers. The MB-nrg PEFs have no explicit expression for three- or higher-body terms. The only term that survive at any n-body level is the electrostatics thorugh the classical polarization.\n",
    "\n",
    "Repulsion, dispersion and electrostatics can be calculated if the monomer properties such as charges, polarizabilities, and dispersion coefficients are known. The MB-nrg models are physically motivated, and all these properties are calculated from electronic structure calculations. Concretely, the charges are calculated by performing a CM5 calculation with $\\omega$B97M-V and aug-cc-pvtz by default. The polarizabilities and C6 are obtained peforming an XDM calculation at the same level of theory, obtaining the C6 coefficients directly from the electronic structure output, and using the effective volumes to calculate the effective polarizability of each atom with the expression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha ^{eff} = \\left( \\alpha^{free} \\frac{V^{eff}}{V^{free}} \\right) ^ {\\frac{4}{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\alpha^{free}$ is the polarizability of the atom by itslef in the gas phase, $V^{free}$ is the volume of that atom in the gas phase, and $V^{eff}$ can be obtained from the XDM calculation, being the volume of the atom in the environment of the molecule. Unfortunately, the user must be advised that QChem 5.1 cannot perform CM5 calculations on charged species, and the XDM module does not accept mixed or user-defined basis sets. This means, for example, that the CM5 charges for an ion like SO$_4^{2-}$ or the C6 coefficient for Cl$^{-}$ -- I$^{-}$ can't be obtained using MB-Fit. A recommended bypass is to use Gaussian16's CM5 method for charged species, and a combination of Gaussian/Postg for the C6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_system_properties` performs the necessary electronic structure calculations to obtain charges, polarizabilities and C6 coefficients (if applicable) for the system.|\n",
    "```\n",
    "get_system_properties(settings_file, config_path, geo_paths, distance_between=20, use_published_polarizabilities=True, method='wb97m-v', basis='aug-cc-pvtz', num_digits=4, virtual_sites=['X', 'Y', 'Z'], use_cm5=True)\n",
    "    Obtains information such as charges and pols that will be needed for the fitting.\n",
    "    \n",
    "    Qchem is required for this step to work.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        config_path         - Local path to file to write the config file to.\n",
    "        geo_paths           - List of local paths to the optimized geometries to include in this fit config.\n",
    "        distance_between    - The Distance between each geometry in the qchem calculation. If the qchem calculation\n",
    "                does not converge, try different values of this.\n",
    "        use_published_polarizabilities - use published polarizabilites from\n",
    "                DOI: 10.1080/00268976.2018.1535143 rather than the ones Marc gave me to use.\n",
    "                Default: True.\n",
    "        method              - Method to use for charges, polarizabilities, and c6 constants.\n",
    "                Default: wb97m-v.\n",
    "        basis               - Basis to use for charges, polarizabilites, and c6 constants.\n",
    "                Default: aug-cc-pvtz.\n",
    "        num_digits            - Number of digits after the decimal point to include in charges, c6, and polarizabilites.\n",
    "                Default: 4\n",
    "        virtual_sites       - List of Symmetry labels that are virtual sites.\n",
    "                Default: [\"X\", \"Y\", \"Z\"]\n",
    "        use_cm5             - Use CM5 charges rather than ChElPG\n",
    "    \n",
    "    Returns:\n",
    "        charges             - List with the charges of each monomer [[mon1],[mon2],..]\n",
    "        pols                - List with the pols of each monomer [[mon1],[mon2],..]\n",
    "        C6                  - List with the C6 constants\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function, the mandatory argument `config_path` is the path to the file where the config file will be written. The last mandatory argument `geo_paths` must be a list containing, in same order as the symmetry, the optimized monomer XYZ file for each monomer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"config.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_nh3, pol_nh3, c6 = mbfit.get_system_properties(settings_nh3, config, geo_paths = [optimized_nh3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the charges have been computed and stored in `chg` from a CM5 calculation on the optimized NH3, the polarizabilites have been computed using the effective volumes on the optimized NH3 and stored in `pol`, and the C6 coefficients have been computed from a XDM calculation on a dimer of NH3, separated a long distance, and stored in `c6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"charges\",chg_nh3)\n",
    "print(\"polarizabilities\",pol_nh3)\n",
    "print(\"C6\",c6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these properties calculated we can now write the configuration file that will be used to control the generation of the fitting code. The file will be written in `config.ini`. If the user has calculated externally the charges, C6 or polarizabilities, they can set those parameters themselves and write the config file with the self-defined constants. If all the parameters are to be defined, the function `get_system_properties` has to be called anyway to set up the template. Once the system properties are set, the config file can be updated with the function `write_config_file`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "write_config_file(settings_file, config_path, charges, pols, geo_paths, C6=[0.0], polfacs=None, d6=None, A=None, kmin=0.0, kmax=50.0, dmin=0.0, dmax=50.0, bmin=0.0, bmax=10.0, kmin_init=1.0, kmax_init=4.0, dmin_init=1.0, dmax_init=4.0, bmin_init=1.0, bmax_init=4.0, r_in=7.0, r_out=8.0, energy_range=20, alpha=0.0005, virtual_sites_label=['X', 'Y', 'Z'], var_intra='exp', var_inter='exp', var_virtual_sites='coul')\n",
    "    Writes the config file.\n",
    "    \n",
    "    Qchem is required for this step to work.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        config_path         - Local path to file to write the config file to.\n",
    "        charges             - List with the charges of each monomer [[mon1],[mon2],..]\n",
    "        pols                - List with the pols of each monomer [[mon1],[mon2],..]\n",
    "        geo_paths           - List of local paths to the optimized geometries to include in this fit config.\n",
    "        C6                  - List with the C6 constants\n",
    "                Default: [0.0]\n",
    "        polfacs             - List with the polarizability factors of each monomer [[mon1],[mon2],..]\n",
    "                Default: None\n",
    "        d6                  - List with the d6 constants\n",
    "                Default: None\n",
    "        A                   - List with the buckingham A parameters\n",
    "                Default:  None\n",
    "        kmin                - Minimum value of k allowed while fitting\n",
    "                Default: 0.0\n",
    "        kmax                - Maximum value of k allowed while fitting\n",
    "                Default: 50.0\n",
    "        dmin                - Minimum value of d allowed while fitting\n",
    "                Default: 0.0\n",
    "        dmax                - Maximum value of d allowed while fitting\n",
    "                Default: 50.0\n",
    "        bmin                - Minimum value of b allowed while fitting\n",
    "                Default: 0.0\n",
    "        bmax                - Maximum value of b allowed while fitting\n",
    "                Default: 10.0\n",
    "        kmin_init           - Minimum value of k allowed in initialization\n",
    "                Default: 1.0\n",
    "        kmax_init           - Maximum value of k allowed in initialization\n",
    "                Default: 4.0\n",
    "        dmin_init           - Minimum value of d allowed in initialization\n",
    "                Default: 1.0\n",
    "        dmax_init           - Maximum value of d allowed in initialization\n",
    "                Default: 4.0\n",
    "        bmin_init           - Minimum value of b allowed in initialization\n",
    "                Default: 1.0\n",
    "        bmax_init           - Maximum value of b allowed in initialization\n",
    "                Default: 4.0\n",
    "        r_in                - Distance at which polynomials start to decay to 0\n",
    "                Default: 7.0\n",
    "        r_out               - Distance at which polynomials are 0\n",
    "                Default: 8.0\n",
    "        energy_range        - Value of DE in the weight expressions: w = (DE/(E-Emin+DE))^2\n",
    "                Default: 20.0\n",
    "        alpha               - Ridge regression parameter\n",
    "                Default: 0.0005\n",
    "        virtual_sites_label - List of Symmetry labels that are virtual sites.\n",
    "                Default: [\"X\", \"Y\", \"Z\"]\n",
    "        var_intra           - Type of variable used for intramolecular distances.\n",
    "                              exp = exp(-kr)\n",
    "                              exp0 = exp(-k(r-r0))\n",
    "                              coul = exp(-kr)/r\n",
    "                              coul0 = exp(-k(r-r0))/r\n",
    "                Default: exp\n",
    "        var_inter           - Type of variable used for intermolecular distances.\n",
    "                              exp = exp(-kr)\n",
    "                              exp0 = exp(-k(r-r0))\n",
    "                              coul = exp(-kr)/r\n",
    "                              coul0 = exp(-k(r-r0))/r\n",
    "                Default: exp\n",
    "        var_virtual_sites   - Type of variable used for distances involving polynomial virtual sites.\n",
    "                              exp = exp(-kr)\n",
    "                              exp0 = exp(-k(r-r0))\n",
    "                              coul = exp(-kr)/r\n",
    "                              coul0 = exp(-k(r-r0))/r \n",
    "                Default: coul\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config file defines all the different features that can be tuned in the fitting procedure and the monomials functional form. The first arguments have already been introduced. The `polfac` argument, which is `None` by default, is a list of the same dimensions as `pol` containing the smearings to use in the Thole model. The advice is to use the default, which will set those values to be the same as the atomic polarizabilities. Although in this example there is no need to do it, since all the pairs inside NH3 are excluded, the values of `A` and `d6` should be the ones from the TTM-nrg PEF. They can be ignored for now. `k_min/max` and `d_min/max`  control which is the minimum and maximum value allowed for the non-linear parameters of the polynomial: `k` and `d`. `b_min/max` controls the maximum and minimum values allowed when fitting the Buckingham potential for the non-linear parameter `b`. The same variants with `init` stablish the limits of the parameters when performing the first guess. The default values for all of them are recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the publications from the Paesani Lab, the polynomial correction for the two-body is applied up to a certain distance. To avoid a sudden change in the potential energy surface, a switch function that smoothly turns off the polynomials is used. In the previous function call, `r_in` and `r_out` are the distances in whcih the switch starts to go to 0, and when the switch is exactly 0, respectively. A 2 Angstrom buffer region starting at 6 or 7 Angstrom is recommended for two-body fits. One-body fits do not use a switch function and these values will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value defined in `energy_range` (`DE` for short) will determine how different is the weight as a function of the energy. The weights are computed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_i = \\left( \\frac{DE}{DE + (BE-BE_{min})} \\right) ^ 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where DE is the energy range, and BE is the binding energy, being BE$_{min}$ the binding energy of the minimum energy structure. This meand than when the difference (BE-BE$_{min}$) is equal to DE, the weight of that configuration will be 0.25, having a maximum of 1.0 when BE = BE$_{min}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `alpha` is the regularization parameter. The fitting procedure uses ridge regression (also known as Tikonov Regularization) to ensure that the linear parameters of the polynomials are not in a wide range of orders of magnitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.write_config_file(settings_nh3, config, chg_nh3, pol_nh3, geo_paths = [optimized_nh3], C6=c6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B MB-nrg fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set and the configuration file are key pieces to be able to perform the fit. Now the fitting code must be generated. The fitting code will be specific for the system that is being studied. The fitting code can be generated with the function `generate_mbnrg_fitting_code`, which will generate a new folder `fit_dir_path` with the source code of the fitting code. If MAPLE is not available, and the optimized polynomial files have not been obtained, one can use the direct gradients by setting `use_direct` to `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_mbnrg_fitting_code(settings_path, config_path, poly_in_path, \n",
    "                            poly_path, poly_order, fit_dir_path, use_direct=False)\n",
    "    Generates the fit code based on the polynomials for a system\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        config_path         - Local path to the dimer config file.\n",
    "        poly_in_path        - Local path to the the A3B2.in type file to read polynomial input from.\n",
    "        poly_path           - Local path to directory where polynomial files are.\n",
    "        poly_order          - The order of the polynomial in poly_path.\n",
    "        fit_dir_path        - Local path to directory to generate fit code in.\n",
    "        use_direct          - If true, it will use the direct polynomials instead of the mapleoptimized\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh3_monomer_fitting_code_dir = \"fitting_code_nh3_mbnrg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_mbnrg_fitting_code(settings_nh3, config, poly_in_nh3, polynomial_directory_nh3, \n",
    "                                  polynomial_order_nh3, nh3_monomer_fitting_code_dir, use_direct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the code can be compiled. If needed, the Makefile inside `nh3_monomer_fitting_code_dir/src` can be modified and manually compile the code and use a different compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.compile_fit_code(settings_nh3,nh3_monomer_fitting_code_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fits will have a random initial guess with random numbers seeded wuth the time. It is strongly recommended to run at least 50 fits,although here we will just run 2 for the sake of the example. Depending on the number of terms and number of variables, the fits might take up to several hours. Thus it is convenient to have each fit prepared in a folder with a script that can be executed locally or in a supercomputer. First, we prepare the fits by calling `prepare_fits`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "prepare_fits(settings_path, fit_dir_path, training_set_path, fits_path, DE=20, alpha=0.0005, num_fits=10, ttm=False, over_ttm=False)\n",
    "    Prepares fits to be run by creating directories with executable scripts in them.\n",
    "    \n",
    "    Each directory will contain a run_fit.sh script, which when ran will run one fit.\n",
    "    \n",
    "    The directories will appear in the directory with your other log files.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        fit_dir_path        - Local path to the directory containing the compiled fitcode.\n",
    "        training_set_path   - Local path to training set to use for all the fits.\n",
    "        fits_path           - Local path to the directory to create the fits in.\n",
    "        DE                  - Low DE places more weight on low energy training set items. \n",
    "                              Large DE places even weight on all training set items. Weights w_n are computed as\n",
    "                              w_n = (DE / (E_n - E_min + DE))**2\n",
    "        alpha               - Weight for the regularization parameter in the fits. Large alpha means coefficients will\n",
    "                be smaller. (Less likely for one or more coefficients to blow up.)\n",
    "        num_fits            - How many new directories with executables to make. Existing ones will not be changed.\n",
    "        ttm                 - True if these are ttm fits. False otherwise.\n",
    "        over_ttm            - Only used if ttm is False, if enabled, will fit polynomials over ttm.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function, `fits_path` is the folder where the fits are going to be set up. DE should be set to the energy_range value, and alpha to the regularization parameter used in the config file. If the fit is a two-body fit, there is the option to use the polynomials purely as a correction on top of the TTM-nrg PEF by setting `over_ttm` to `True`. If `False`, the polynomials will take care of the repulsion and the correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_nh3_monomer = \"fits_nh3_monomer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.prepare_fits(settings_nh3, nh3_monomer_fitting_code_dir, training_set,fits_nh3_monomer,num_fits = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous function has generated several folders inside `fits_nh3_monomer`, with a `run.sh` script that can be executed externally if needed. MB-Fit provides with a function that will loop over the unconverged fits and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.execute_fits(settings_nh3,fits_nh3_monomer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after the fits are done, the `retrieve_best_fit` function will look for the best fit and keep it in a separate folder called `best_fit`. The arguments of this function `fitted_nc_path` and `fitted_ttmnrg_params` are the paths to the files that will contain the encoded MB-nrg and TTM-nrg parameters respectively. Recommended to leave it as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "retrieve_best_fit(settings_path, fits_path, fitted_nc_path='mbnrg.nc', fitted_ttmnrg_params='ttm-nrg_params.dat')\n",
    "    Looks through all log files in all fit directories in the log path and finds the best fit.\n",
    "    \n",
    "    The best_fit will end up inside a directory in the logs directory called \"best_fit\".\n",
    "    \n",
    "    If any new fit is better than the current best fit, it will replace best_fit with the new\n",
    "    best one.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        fits_path           - Local path to the directory to create the fits in.\n",
    "        fitted_nc_path      - Generate a .nc file with the parameters for the best fit at this location.\n",
    "        fitted_ttmnrg_params - Rename the output where the TTM-nrg params are to this name\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.retrieve_best_fit(settings_nh3,fits_nh3_monomer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last function has printed the weighted RMSD of the full training set, the low eneergy RMSD, which is the RMSD of configurations with binding energy below DE, and the maximum error in the low energy training set. If the RMSD is higher than the target one, a solution is to increase the polynomial degree at the cost of having larger polynomials, larger training sets, and increased evaluation time of the polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the fits are done and there is a fit that meets our expectations, one can plot the correlation plots for the training and the test set using the tools provided in MB-fit with the function `get_correlation_data`. The function will return a list of energies that can be written and plotted with other programs, although it will save a plot properly formated generated with MatPlotLib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "get_correlation_data(settings_path, fitting_code_dir_path, fits_path, training_set, split_energy=None, min_energy_plot=0.0, max_energy_plot=50.0, correlation_prefix='correlation', correlation_directory='correlation', minor_tick=5.0, colors=None, labels=None, ttm=False, over_ttm=False, nc_path='mbnrg.nc', fitted_ttmnrg_params='ttm-nrg_params.dat', max_1b=100.0)\n",
    "    Generates correltation data for the training/test set passed as argument\n",
    "    \n",
    "    Args:\n",
    "        settings_path         - Local path to the file containing all relevent settings information.\n",
    "        fitting_code_dir_path - Local path to the directory containing the compiled fitcode.\n",
    "        fits_path             - Local path to folder containing the fits\n",
    "        training_set          - Configurations to evaluate. They need the binding energy and n-b energy in this order in the comment line.\n",
    "        split_energy          - If not None, will split the correlation plot in two sets, low and high, depending on the value of the variable.\n",
    "        min_energy_plot       - Lower bound of the energy in the plot\n",
    "        max_energy_plot       - Upper bound of the energy in the plot\n",
    "        correlation_prefix    - Prefix for the correlation files that will be generated.\n",
    "        correlation_directory - Directory where all the correlation files will be put.\n",
    "        minor_tick            - Interval of the minor ticks in the plot\n",
    "        colors                - List of two elements with the colors for low energy and high energy in the correlation plot\n",
    "        labels                - List of two elements with the x-axis and y-axis labels\n",
    "        ttm                   - True if these are ttm fits. False otherwise.\n",
    "        over_ttm              - Only used if ttm is False, if enabled, will fit polynomials over ttm.\n",
    "        nc_path               - Netcdf file with the parameters for the best fit.\n",
    "        fitted_ttmnrg_params  - Name of the output where the TTM-nrg params\n",
    "        max_1b                - Maximum deformation energy allowed in the plot (IE - BE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the arguments of this function have already been described. The data and plot generated will have two data sets: the low energy set and the high energy set. The limit is set by the `split_energy` value if defined. If not defined, the whole training set will be plotted as one set. Then there are some formatting options for the plot to allow the user to customize it. However, one can always get the energies returned and plot them with their favorite plotting software. The plots will be stored in `correlation_directory` with the prefix `correlation_prefix`. `min_energy_plot` and `max_energy_plot` define the limits of the energies shown in the plot, and `minor_tick` is the frequency of the minor tick, being the major twice that value. By default, the colors used are greens for MB-nrg and oranges for TTM-nrg, but the user can specify a list of two elements with named colors to plot the low and high energy correlation data. By default, the labels are `\"Reference\"` for the x-axis and `\"MB-nrg\"` or `\"TTM-nrg\"` for the y-axis, which can be overwritten by setting a list of two elements in the `labels` argument. In terms of formatting, although not important in 1B fits, one can also define the maximum binging energy of the configurations included in the correlation plot by setting `max_1b`. Specially with floppy molecules, it is possible that some dimers have a two-body energy that is negative, but the distortion of the molecules is huge, resulting in a high binding energy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies_training = mbfit.get_correlation_data(settings_nh3, nh3_monomer_fitting_code_dir, fits_nh3_monomer,\n",
    "                                               training_set, split_energy = 10.0, \n",
    "                                               min_energy_plot=0.0, max_energy_plot=30.0,\n",
    "                                               correlation_prefix=\"correlation_1b_nh3\",\n",
    "                                              correlation_directory = \"correlation_1b_nh3\",\n",
    "                                              minor_tick = 2.5, colors = ['black','darkgreen'],\n",
    "                                              labels = [\"This is the X-axis\", \"And this the Y axis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "energies_test = mbfit.get_correlation_data(settings_nh3, nh3_monomer_fitting_code_dir, fits_nh3_monomer,\n",
    "                                           test_set, split_energy = 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "retrieve_best_fit(settings_path, fits_path, fitted_nc_path='mbnrg.nc', fitted_ttmnrg_params='ttm-nrg_params.dat')\n",
    "    Looks through all log files in all fit directories in the log path and finds the best fit.\n",
    "    \n",
    "    The best_fit will end up inside a directory in the logs directory called \"best_fit\".\n",
    "    \n",
    "    If any new fit is better than the current best fit, it will replace best_fit with the new\n",
    "    best one.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        fits_path           - Local path to the directory to create the fits in.\n",
    "        fitted_nc_path      - Generate a .nc file with the parameters for the best fit at this location.\n",
    "        fitted_ttmnrg_params - Rename the output where the TTM-nrg params are to this name\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Add files to MBX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:** The order in which PEFs should be obtained and implemented is always 1) One-body, 2) Two-Body TTM-nrg, 3) 2B MB-nrg. Please don't try anything else unless you know what are you doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have generated a 1B MB-nrg PEF for ammonia! However, it will be complicated to use directly from the fitting code. MB-Fit has an automatic interface to MBX that allows the automatic implementation of all the information needed for the PEF inside MBX. This step is important and it is necessary to check for correctness after the implementation has been completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless you are an expert, please follow this recommended procedure for the PEFs implementation in MBX.\n",
    "1. Make a fresh clone of your MBX fork.\n",
    "2. Create a new branch in MBX with the name `master-Xb-YYY`, where X is the n-body term you are implementing, and YYY is the monomer, dimer.. used. In this case, the branch will be `master-1b-nh3`. The command used is `git checkout -b master-1b-nh3`\n",
    "3. Run the `generate_MBX_files` function, pointing to the correct MBX_HOME directory.\n",
    "4. Add all the new files and changes to existing files to the branch with `git add file1.cpp file2.h ...`, and commit the changes. If you want to know which files are new and modified, run `git status` inside the MBX repo, right after running the MBFIT function. That will list all the new (untracked) files and the modified ones. Add all of them. Commit the changes with `git commit -m \"Added nh3 files\"`\n",
    "5. Compile MBX from scratch.\n",
    "6. Test that the PEF is properly implemented by calculating the energy of a random monomer in the training set with MBX and the `eval` executable inside the fitting code bin directory.\n",
    "7. If everything is working, make sure everything is commited to the branch, and go to master (`git checkout master`) and merge that branch (`git merge master-Xb-YYY`).\n",
    "8. Push your MBX master branch to your fork for safekeeping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to set `MBX_HOME` as `None` and add manually the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(mbfit.generate_MBX_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything here in this function is known except for the `mon_ids`, which is a list on n elements (as many as the n-body term calculated) with the id that your monomer will have in MBX. For example, H$_2$O is `\"h2o\"`, and Na$^+$ is `\"na\"`. We will define NH$_3$ as `\"nh3\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_ids = [\"nh3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_MBX_files(settings_nh3, config, mon_ids, polynomial_order_nh3,\n",
    "                                     do_ttmnrg=False, mbnrg_fits_path=fits_nh3_monomer,  \n",
    "                                     MBX_HOME = None, version = \"v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Body TTM-nrg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually the system of interest is not a single monomer, but how a monomer interacts with other monomers either in gas phase or condensed phase. To achieve that goal, a part from the monomer distortions, it is needed an energy function that describes the interaction between molecules. Many approaches have been defined along the years. In the MB-nrg/TTM-nrg framework, one can chose between the classical description (TTM-nrg) or the quantum effects corrected version (MB-nrg). This section will walk you along the proces of obtaining the TTM-nrg PEF. \n",
    "\n",
    "Although it was not mentioned earlier, if the molecule is big (atom distances of more than 3 bonds), then there will be non-bonded interactions inside the monomer, and this code should not be used for that system without being extremely careful. Also, the 2B TTM-nrg PEF for the homodimer of the big molecule must be obtained before the 1B PEF can be calculated. For small molecules such as NH$_3$, CH$_3$CN, CH$_4$, and so on, this does not apply and the standard protocol can be followed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2B TTM-nrg PEF defines the energy as a sum of 4 contributions:\n",
    "\n",
    "$$V_{TTM}^{2B} = V_{rep}^{2B} + V_{disp}^{2B} + V_{elec}^{2B} + V_{ind}^{2B}$$\n",
    "\n",
    "The two last terms,  $V_{elec}^{2B}$ and $V_{ind}^{2B}$ depend only on the charges, polarizabilities and polarizability factors, and there is nothing to be fit in there. Contrarely, some parameters in the dispersion and the repulsion part must be obtained. \n",
    "\n",
    "The dispersion energy $V_{disp}^{2B}$ for a given pair of atoms i,j is defined as\n",
    "\n",
    "$$V_{ij} = -f(\\delta _{AB} r_{ij})\\frac{C_{6,AB}}{r_{ij}^6}$$\n",
    "\n",
    "where A and B are the atom types of atoms i and j, respectively, and $f(\\delta _{AB} r_{ij})$ is the Tang-Toennies damping function. From this equation, only $\\delta _{AB}$ is unknown and must be fitted, since $C_6$ is obtained from *ab initio* calculations. \n",
    "\n",
    "The repulsion energy (Born-Mayer repulsion,$ V_{rep}^{2B}$) for a given pair i,j is defined as\n",
    "\n",
    "$$V_{ij} = A_{AB} \\exp(-b_{AB}r_{ij})$$\n",
    "\n",
    "where $A_{AB}$ and $b_{AB}$ are unknown.\n",
    "\n",
    "Within our framework, we enforce $\\delta _{AB} = b_{AB}$, so for each unique pair type there are two unkown parameters that will be fitted: $A_{AB}$ and $b_{AB}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Set generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2B TTM-nrg PEF does not have any intramolecular terms in it, thus it is not needed to add distorted monomers and the training set can be generated just using the otimized geometry and setting the two monomers at different distances with random rotations. First of all, we need to define the target monomer pair, and obtain their optimized geometry. In our case, we will use NH$_3$ and H$_2$O (where water will be described using the excellent MB-pol surface). We need to define and redefine some variables. Since there are 2 monomers now, the lists will have two elements. It is important to keep the same order for the monomers along the full process. In this case, the first monomer will be NH$_3$ and the second monomer H$_2$O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names that will identify the monomers. This is used for identification purposes only.\n",
    "names = [\"NH3\",\"H2O\"]\n",
    "\n",
    "# Number of atoms of each monomer\n",
    "number_of_atoms = [4,3]\n",
    "\n",
    "# Charge of each monomer\n",
    "charges = [0,0]\n",
    "\n",
    "# Spin multiplicity of each monomer\n",
    "spin = [1,1]\n",
    "\n",
    "# Use MB-pol for water (if applicable). \n",
    "# If 1 will use the Partridge-Shwenke PEF for water, with the position dependent charges.\n",
    "use_mbpol = [0,1]\n",
    "\n",
    "# Symmetry of the molecule\n",
    "symmetry = [\"A1B3\", \"C1D2X2\"]\n",
    "\n",
    "# SMILES string\n",
    "smiles = [\"N(H)(H)H\", \"O(H)H\"]\n",
    "\n",
    "# System key\n",
    "molecule_in = \"_\".join(symmetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that now, for the `use_mbpol` variable, we set the second element to be 1, since we wan't to use MB-pol to describe water. If set to 0, then the corresponding level of theory will be used to get the water properties. Another feature that is new is the introduction of lone pairs. Although they are only defined if the monomer is water, the user can decide to use or not to use them for their PEFs. The TTM-nrg PEF could be obtained either way, since there are no lone pairs in TTM-nrg, but they will be used later for the MB-nrg PEF. More details will also be given in the MB-nrg section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for monomer\n",
    "settings_h2o = \"settings_h2o_monomer.ini\"\n",
    "\n",
    "my_settings_file = \"\"\"\n",
    "[files]\n",
    "# Local path directory to write log files in\n",
    "log_path = \"\"\" + log_path + \"\"\"\n",
    "\n",
    "[config_generator]\n",
    "# what library to use for geometry optimization and normal mode generation\n",
    "code = \"\"\" + code + \"\"\"\n",
    "# use geometric or linear progression for T and A in config generation, exactly 1 must be True\n",
    "geometric = False\n",
    "linear = False\n",
    "\n",
    "[energy_calculator]\n",
    "# what library to use for energy calculations\n",
    "code = \"\"\" + code + \"\"\"\n",
    "\n",
    "[psi4]\n",
    "# memory to use when doing a psi4 calculation\n",
    "memory = \"\"\" + memory + \"\"\"\n",
    "# number of threads to use when executing a psi4 calculation\n",
    "num_threads = \"\"\" + str(num_threads) + \"\"\"\n",
    "\n",
    "[qchem]\n",
    "# number of threads to use when executing a qchem calculation\n",
    "num_threads = \"\"\" + str(num_threads) + \"\"\"\n",
    "\n",
    "[molecule]\n",
    "# name of fragments, seperated by commas\n",
    "names = \"\"\" + names[1] + \"\"\"\n",
    "# number of atoms in each fragment, seperated by commas\n",
    "fragments = \"\"\" + str(number_of_atoms[1]) + \"\"\"\n",
    "# charge of each fragment, seperated by commas\n",
    "charges = \"\"\" + str(charges[1]) + \"\"\"\n",
    "# spin multiplicity of each fragment, seperated by commas\n",
    "spins = \"\"\" + str(spin[1]) + \"\"\"\n",
    "# tag when putting geometries into database\n",
    "tag = none\n",
    "# Use or not MB-pol\n",
    "use_mbpol = \"\"\" + str(use_mbpol[1]) + \"\"\"\n",
    "# symmetry of each fragment, seperated by commas\n",
    "symmetry = \"\"\" + symmetry[1] + \"\"\"\n",
    "SMILES = \"\"\" + smiles[1] + \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file:\n",
    "ff = open(settings_h2o,'w')\n",
    "ff.write(my_settings_file)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XYZ file that contains the unoptimized geommetry of monomer 1\n",
    "unoptimized_h2o = \"h2o.xyz\"\n",
    "\n",
    "my_unopt_monomer = \"\"\"3\n",
    "unoptimized h2o\n",
    " O                 -0.79953653    0.30706836    0.00000000\n",
    " H                 -0.46621464   -0.63574472    0.00000000\n",
    " H                 -0.46619743    0.77846854    0.81649673\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file:\n",
    "ff = open(unoptimized_h2o,'w')\n",
    "ff.write(my_unopt_monomer)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_h2o = \"h2o_opt.xyz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Ammonia was already optimized in the first part, we can reuse that structure, and just reoptimize water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.optimize_geometry(settings_h2o, unoptimized_h2o, optimized_h2o, method, basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a settings file for the monomers defined, but we need a settings file for the dimer. It looks very similar to the monomer one, except that now the `molecule` section will have 2 elements for each entry, separated by a comma, instead of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for dimer\n",
    "dim_settings = \"dimer_settings.ini\"\n",
    "\n",
    "my_settings_file_dim = \"\"\"\n",
    "[files]\n",
    "# Local path directory to write log files in\n",
    "log_path = \"\"\" + log_path + \"\"\"\n",
    "\n",
    "[config_generator]\n",
    "# what library to use for geometry optimization and normal mode generation\n",
    "code = \"\"\" + code + \"\"\"\n",
    "# use geometric or linear progression for T and A in config generation, exactly 1 must be True\n",
    "geometric = False\n",
    "linear = False\n",
    "\n",
    "[energy_calculator]\n",
    "# what library to use for energy calculations\n",
    "code = \"\"\" + code + \"\"\"\n",
    "\n",
    "[psi4]\n",
    "# memory to use when doing a psi4 calculation\n",
    "memory = \"\"\" + memory + \"\"\"\n",
    "# number of threads to use when executing a psi4 calculation\n",
    "num_threads = \"\"\" + str(num_threads) + \"\"\"\n",
    "\n",
    "[qchem]\n",
    "# number of threads to use when executing a qchem calculation\n",
    "num_threads = \"\"\" + str(num_threads) + \"\"\"\n",
    "\n",
    "[molecule]\n",
    "# name of fragments, seperated by commas\n",
    "names = \"\"\" + names[0] + \",\" + names[1] + \"\"\"\n",
    "# number of atoms in each fragment, seperated by commas\n",
    "fragments = \"\"\" + str(number_of_atoms[0]) + \"\"\",\"\"\" + str(number_of_atoms[1]) + \"\"\"\n",
    "# charge of each fragment, seperated by commas\n",
    "charges = \"\"\" + str(charges[0]) + \"\"\",\"\"\" + str(charges[1]) + \"\"\"\n",
    "# spin multiplicity of each fragment, seperated by commas\n",
    "spins = \"\"\" + str(spin[0]) + \"\"\",\"\"\" + str(spin[1]) + \"\"\"\n",
    "# tag when putting geometries into database\n",
    "tag = none\n",
    "# Use or not MB-pol\n",
    "use_mbpol = \"\"\" + str(use_mbpol[0]) + \"\"\",\"\"\" + str(use_mbpol[1]) + \"\"\"\n",
    "# symmetry of each fragment, seperated by commas\n",
    "symmetry = \"\"\" + symmetry[0] + \"\"\",\"\"\" + symmetry[1] + \"\"\"\n",
    "SMILES = \"\"\" + smiles[0] + \"\"\",\"\"\" + smiles[1] + \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = open(dim_settings,'w')\n",
    "ff.write(my_settings_file_dim)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the optimized monomers and the settings file generated, we can now proceed to generate the training set using the function `generate_2b_configurations`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_2b_configurations(settings_path, geo1_path, geo2_path, number_of_configs, configurations_path, min_distance=1, max_distance=5, min_inter_distance=0.8, progression=False, use_grid=False, step_size=0.5, num_attempts=100, logarithmic=False, distribution=None, mol1_atom_index=None, mol2_atom_index=None, seed=None)\n",
    "    Generates 2b configurations for a given dimer by rotating them randomly over a distribution of\n",
    "    distances.\n",
    "    \n",
    "    If one of mol1_atom_index is specified, then both must be specified.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        geo1_path           - Local path to read the first optimized geometry from.\n",
    "        geo2_path           - Local path to read the second optimized geometry from.\n",
    "        number_of_configs   - The target number of configurations to generate. If max_distance is set too low or \n",
    "                min_inter_distance is set too high, then less configurations may be generated.\n",
    "        configurations_path - Local path to the file in to write the configurations to.\n",
    "        min_distance        - The minimum distance between the centers of mass of the two molecules in any\n",
    "                configuration.\n",
    "        max_distance        - The maximum distance between the centers of mass of the two molecules in any\n",
    "                configuration.\n",
    "        min_inter_distance  - Minimum intermolecular distance in any config is the sum of two atoms vdw radii * this\n",
    "                value.\n",
    "        progression         - If True, use a linear progression for distance between atoms, otherwise random\n",
    "                progression.r\n",
    "        use_grid            - If False, configurations are space roughly evenly between min_distance and max_distance.\n",
    "                If True, then configurations are placed at intervals along this distance based on step_size.\n",
    "        step_size           - If use_grid is True, then this dictates the distance of the spacing interval used to\n",
    "                place the centers of masses of the molecules. Otherwise, this parameter has no effect.\n",
    "        num_attempts        - The number of tries to generate a config at any given distance before giving up and\n",
    "                moving to the next one.\n",
    "        logarithmic         - If True, then a logarithmic progression is used to generate the configurations.\n",
    "                This means more configs are generated at lower distances.\n",
    "        distribution        - An implementation of DistributionFunction. If specified, the logarithmic argument\n",
    "                is ignored and this distribution is used to choose the distances between configurations. Should\n",
    "                be implemented over the domain [0,1]. So the first config will have distance\n",
    "                distribution.get_value(0) and the last config will have distance distribution.get_value(1).\n",
    "        mol1_atom_index     - If specified, then the first molecule will be centered around the atom at this index\n",
    "                rather than its center of mass.\n",
    "        mol2_atom_index     - If specified, then the second molecule will be centered around the atom at this index\n",
    "                rather than its center of mass.\n",
    "        seed                - The same seed will generate the same configurations.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will generate `number_of_configs` configurations, and write them in the file specified in `configurations_path`. The variables `min_distance` and `max_distance` defines the range of center of mass (COM) distances that will be included in the training set. **ETHAN, what exactly is the progression? I think I will leave to you the explanation of this function** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, it is better to use a logarithmic distribution when generating two-body  training sets. The potential energy surface has drastic changes with small displacements of the atoms at short range, while at long range the changes are smoother. thus, one needs more configurations at the short range and less at long range. Another advice when generating these training sets is that eventhough the default value of the minimum intermolecular distance is usually enough, having a value of 0.5 might help if the training set doesn't yield enough repulsive configurations. \n",
    "\n",
    "The number of configurations for the training set of TTM-nrg PEFs is recommended to be around 100-200 times the number of linear parameters to fit, which even if it is larger than the recommended for MB-nrg (20 times the number of linear parameters), it usually yields way less configurations. In this case, ammonia has two atom types (N,H) and water has also two (O,H), being a total of 4 unique pairs and, consequently, 4 linear parameters to fit. For this example we will use 400 configurations. The number of test configurations should be 20% of the training configurations.\n",
    "\n",
    "Let's set the parameters and run the training set generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_configs = 400\n",
    "num_test_configs = 0.2*num_training_configs\n",
    "training_configs = \"ttm_2b_training_configs.xyz\"\n",
    "test_configs = \"ttm_2b_test_configs.xyz\"\n",
    "training_set_ttm = \"ttm_2b_training_set.xyz\"\n",
    "test_set_ttm = \"ttm_2b_test_set.xyz\"\n",
    "min_d_2b = 1.0\n",
    "max_d_2b = 9.0\n",
    "min_inter_d = 0.5\n",
    "seed_training = 101010\n",
    "seed_test = 10101\n",
    "bind_emax = 150.0\n",
    "mon_emax = 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "mbfit.generate_2b_configurations(dim_settings, optimized_nh3, optimized_h2o, \n",
    "                                 num_training_configs, training_configs, \n",
    "                                 min_distance = min_d_2b, \n",
    "                                 max_distance = max_d_2b, \n",
    "                                 min_inter_distance = min_inter_d, \n",
    "                                 progression = True, logarithmic = True,\n",
    "                                 seed = seed_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "mbfit.generate_2b_configurations(dim_settings, optimized_nh3, optimized_h2o, \n",
    "                                 num_test_configs, test_configs, \n",
    "                                 min_distance = min_d_2b, \n",
    "                                 max_distance = max_d_2b, \n",
    "                                 min_inter_distance = min_inter_d, \n",
    "                                 progression = True, logarithmic = True,\n",
    "                                 seed = seed_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, analogously to the one-body configurations, we will add them to the database and calculate the energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "mbfit.init_database(dim_settings, database_settings, \n",
    "                                training_configs, method, basis, \n",
    "                                cp, \"training_nh3h2ottm\", optimized = False)\n",
    "# Test Set\n",
    "mbfit.init_database(dim_settings, database_settings, \n",
    "                                test_configs, method, basis, \n",
    "                                cp, \"test_nh3h2ottm\", optimized = False)\n",
    "# Add monomer optimized geommetry to database (needed for binding energy)\n",
    "mbfit.init_database(settings_nh3, database_settings, optimized_nh3, \n",
    "                                method, basis, cp, \"training_nh3h2ottm\", optimized = True)\n",
    "mbfit.init_database(settings_h2o, database_settings, optimized_h2o, \n",
    "                                method, basis, cp, \"training_nh3h2ottm\", optimized = True)\n",
    "mbfit.init_database(settings_nh3, database_settings, optimized_nh3, \n",
    "                                method, basis, cp, \"test_nh3h2ottm\", optimized = True)\n",
    "mbfit.init_database(settings_h2o, database_settings, optimized_h2o, \n",
    "                                method, basis, cp, \"test_nh3h2ottm\", optimized = True)\n",
    "\n",
    "# Fill the database\n",
    "mbfit.fill_database(dim_settings,  database_settings, client_name, \"training_nh3h2ottm\", \"test_nh3h2ottm\")\n",
    "\n",
    "# Generate training set\n",
    "mbfit.generate_training_set(dim_settings, database_settings, training_set_ttm, \n",
    "                                        method, basis, cp, \"training_nh3h2ottm\", \n",
    "                                        e_bind_max = bind_emax, e_mon_max = mon_emax)\n",
    "\n",
    "# Generate test set\n",
    "mbfit.generate_training_set(dim_settings, database_settings, test_set_ttm, \n",
    "                                        method, basis, cp, \"test_nh3h2ottm\", \n",
    "                                        e_bind_max = bind_emax, e_mon_max = mon_emax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate System properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the training and test sets generated, the last step before we can proceed witht the fitting is to get the charges, pols and polfacs. In this case, ammonia was previously calculated, and **the same ammonia properties must be used for any PEF involving NH$_3$**. Thus that data will be calculated, but reused from the 1B fit to ensure compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dimer = \"config_dimer.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_dimer, pol_dimer, c6_dimer = mbfit.get_system_properties(dim_settings, config_dimer, \n",
    "                                                             geo_paths = [optimized_nh3, optimized_h2o])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, from this previous calculation only the C6 will be used. The final charges, pols and polfacs will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chg = [chg_nh3[0],[0.0,0.0,0.0]]\n",
    "final_pol = [pol_nh3[0],[0.0,0.0,0.0]]\n",
    "final_c6 = c6_dimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.write_config_file(dim_settings, config_dimer, final_chg, final_pol, \n",
    "                        [optimized_nh3, optimized_h2o], final_c6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTM-nrg Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the configuration file properly generated, we can now proceed with the fitting. The function calls are the same as for the one-body MB-nrg case, with slight differences to run a TTM fit instead of an MB-nrg fttmit. The function `generate_ttmnrg_fitting_code` will be called instead of the `generate_mbnrg_fitting_code`, and the TTM flag `ttm` will be set to `True`. Again, although it is recomended to run 50 fits, this example will only run 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttmnrg_directory = \"2b_ttm-nrg_fitting_code\"\n",
    "ttmnrg_fits_dir = \"2b_ttm-nrg_fits\"\n",
    "num_ttm_fits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_ttmnrg_fitting_code(dim_settings, config_dimer, ttmnrg_directory)\n",
    "\n",
    "mbfit.compile_fit_code(dim_settings, ttmnrg_directory)\n",
    "\n",
    "mbfit.prepare_fits(dim_settings, ttmnrg_directory, \n",
    "                               training_set_ttm, ttmnrg_fits_dir, \n",
    "                               DE=20, alpha=0.0005, num_fits=num_ttm_fits, \n",
    "                               ttm=True, over_ttm=False)\n",
    "\n",
    "mbfit.execute_fits(dim_settings, ttmnrg_fits_dir)\n",
    "\n",
    "mbfit.retrieve_best_fit(dim_settings, ttmnrg_fits_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the best fit is obtained, the config file must be updated with the fitted parameters. To do so, a simple call to `update_config_with_ttm` will do the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.update_config_with_ttm(dim_settings, ttmnrg_fits_dir, config_dimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to how the one-body MB-nrg PEF correlation plot was obtained, the TTM-nrg correlation plot can also be drawn with the function `get_correlation_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies_test = mbfit.get_correlation_data(dim_settings, ttmnrg_directory, ttmnrg_fits_dir,\n",
    "                                           test_set_ttm, split_energy = 10.0,ttm=True,\n",
    "                                           min_energy_plot=-10.0, max_energy_plot=30.0,\n",
    "                                               correlation_prefix=\"correlation_2b_nh3h2o_ttm_test\",\n",
    "                                              correlation_directory = \"correlation_2b_nh3h2o_ttm_test\")\n",
    "energies_test = mbfit.get_correlation_data(dim_settings, ttmnrg_directory, ttmnrg_fits_dir,\n",
    "                                           training_set_ttm, split_energy = 10.0,ttm=True,\n",
    "                                           min_energy_plot=-10.0, max_energy_plot=50.0,\n",
    "                                               correlation_prefix=\"correlation_2b_nh3h2o_ttm_train\",\n",
    "                                              correlation_directory = \"correlation_2b_nh3h2o_ttm_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the wrapper to add the PEF to MBX can be called. Note that the degree is set to `0` as it could have been set to anything else. TTM-nrg does not care about the degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_ids = [\"nh3\",\"h2o\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_MBX_files(dim_settings, config_dimer, mon_ids, 0, do_ttmnrg = True, \n",
    "                         MBX_HOME = None, version = \"v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Body MB-nrg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final PEF one can get is the MB-nrg PEF. As has been shown in [multiple publications](http://paesanigroup.ucsd.edu/), MB-nrg is able to reproduce within chemical accuracy any reference data. \n",
    "\n",
    "The two-body MB-nrg PEF is defined in a similar way as the TTM-nrg PEF:\n",
    "\n",
    "$$V_{MB}^{2B} = V_{poly}^{2B} + V_{disp}^{2B} + V_{elec}^{2B} + V_{ind}^{2B}$$\n",
    "\n",
    "MB-Fit allows the fitting of the polynomials over the full TTM-nrg PEF (called over-ttm) or ignoring the repulsion of TTM-nrg and fitting the polynomials to also to account for that. Thus we can define\n",
    "\n",
    "$$V_{MB,over-ttm}^{2B} = V_{poly}^{2B} + V_{rep}^{2B} + V_{disp}^{2B} + V_{elec}^{2B} + V_{ind}^{2B}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial generation can be performed analogously to the one-body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_in_dim = \"dimer_poly.in\"\n",
    "polynomial_order_dimer = 2\n",
    "polynomial_directory_dimer = \"polynomial_generation_dimer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_poly_input(dim_settings, molecule_in, poly_in_dim)\n",
    "mbfit.generate_polynomials(dim_settings, poly_in_dim, polynomial_order_dimer, \n",
    "                                       polynomial_directory_dimer, generate_direct_gradients=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Set generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure proper description of the configurational space, the training set will be generated from three different sources:\n",
    "1. The first one will be similar to the TTM-nrg training set. The optimized monomers will be used to create scans along the COM distances.\n",
    "2. Analogous to the first one, but instead of using the optimized geometries of the monomers, a set of distorted monomers will be generated from the normal modes, and will be used to create the scans.\n",
    "3. For each different local minima and transition state of the dimer, normal modes configurations will be generated.\n",
    "\n",
    "The recommended distribution along the three sets is 35% of rigid scan, 50% of flexible scan, and 15% of normal mode, with a total number of configurations around 20 times the number of linear parameters (terms) in the polynomial. Since the polynomial of degree 2 is small, we will use a slightly larger amount of configurations. If more than one minimum / transition state is found, then each configuration will be a fraction of the total normal mode configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_mbnrg_training_configs = 800\n",
    "num_total_mbnrg_test_configs = 200\n",
    "\n",
    "num_rigid_train_configs = int(0.35*num_total_mbnrg_training_configs)\n",
    "num_flex_train_configs = int(0.5*num_total_mbnrg_training_configs)\n",
    "num_nm_train_configs = int(0.15*num_total_mbnrg_training_configs)\n",
    "\n",
    "num_rigid_test_configs = int(0.35*num_total_mbnrg_training_configs)\n",
    "num_flex_test_configs = int(0.5*num_total_mbnrg_training_configs)\n",
    "num_nm_test_configs = int(0.15*num_total_mbnrg_training_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rigid configurations can be obtained as the training set for TTM-nrg was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_configs = \"rigid_configs_train.xyz\"\n",
    "test_configs = \"rigid_configs_test.xyz\"\n",
    "min_d_2b = 1.0\n",
    "max_d_2b = 9.0\n",
    "min_inter_d = 0.5\n",
    "seed_training = 123\n",
    "seed_test = 543\n",
    "bind_emax = 150.0\n",
    "mon_emax = 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "mbfit.generate_2b_configurations(dim_settings, optimized_nh3, optimized_h2o, \n",
    "                                 num_rigid_train_configs, training_configs, \n",
    "                                 min_distance = min_d_2b, \n",
    "                                 max_distance = max_d_2b, \n",
    "                                 min_inter_distance = min_inter_d, \n",
    "                                 progression = True, logarithmic = True,\n",
    "                                 seed = seed_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "mbfit.generate_2b_configurations(dim_settings, optimized_nh3, optimized_h2o, \n",
    "                                 num_rigid_test_configs, test_configs, \n",
    "                                 min_distance = min_d_2b, \n",
    "                                 max_distance = max_d_2b, \n",
    "                                 min_inter_distance = min_inter_d, \n",
    "                                 progression = True, logarithmic = True,\n",
    "                                 seed = seed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "mbfit.init_database(dim_settings, database_settings, \n",
    "                                training_configs, method, basis, \n",
    "                                cp, \"training_nh3h2omb\", optimized = False)\n",
    "# Test Set\n",
    "mbfit.init_database(dim_settings, database_settings, \n",
    "                                test_configs, method, basis, \n",
    "                                cp, \"test_nh3h2omb\", optimized = False)\n",
    "# Add monomer optimized geommetry to database (needed for binding energy)\n",
    "mbfit.init_database(settings_nh3, database_settings, optimized_nh3, \n",
    "                                method, basis, cp, \"training_nh3h2omb\", optimized = True)\n",
    "mbfit.init_database(settings_h2o, database_settings, optimized_h2o, \n",
    "                                method, basis, cp, \"training_nh3h2omb\", optimized = True)\n",
    "mbfit.init_database(settings_nh3, database_settings, optimized_nh3, \n",
    "                                method, basis, cp, \"test_nh3h2omb\", optimized = True)\n",
    "mbfit.init_database(settings_h2o, database_settings, optimized_h2o, \n",
    "                                method, basis, cp, \"test_nh3h2omb\", optimized = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the flexible configurations, the normal modes of the monomers need to be calculated, so that a set of distorted configurations can be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_modes_h2o = \"normal_modes_h2o.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_normal_modes(settings_h2o, optimized_h2o, normal_modes_h2o, method, basis, qchem_qm_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the normal modes for ammonia were already generated, there is no need to recalculate them. Now the set of distorted monomers can be generated by calling the same function used to generate the one-body training set. The number of configurations to generate should be ~20% of the total number of training configurations. Although it would not be necessary to calculate the energy for these configurations, it is recommended to do so to filter out any extremely distroted non-physical configuration. However, it is adviced to sample the normal modes at high temperature using a constant distribtuion if the PEF is going to be used in high pressure and high temperature simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distorted_nh3 = \"distorted_nh3.xyz\"\n",
    "distorted_h2o = \"distorted_h2o.xyz\"\n",
    "num_distorted = int(0.2 * num_total_mbnrg_training_configs)\n",
    "screened_configurations_nh3 = \"screened_distorted_nh3.xyz\"\n",
    "screened_configurations_h2o = \"screened_distorted_h2o.xyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_normal_mode_configurations(settings_nh3, optimized_nh3, normal_modes_nh3, \n",
    "                                          distorted_nh3, number_of_configs=num_distorted, \n",
    "                                          seed=seed_training, classical=classical)\n",
    "mbfit.generate_normal_mode_configurations(settings_h2o, optimized_h2o, normal_modes_h2o, \n",
    "                                          distorted_h2o, number_of_configs=num_distorted, \n",
    "                                          seed=seed_training, classical=classical)\n",
    "\n",
    "mbfit.init_database(settings_nh3, database_settings, \n",
    "                                distorted_nh3, method, basis, \n",
    "                                cp, \"distorted_nh3\", optimized = False)\n",
    "mbfit.init_database(settings_h2o, database_settings, \n",
    "                                distorted_h2o, method, basis, \n",
    "                                cp, \"distorted_h2o\", optimized = False)\n",
    "mbfit.init_database(settings_h2o, database_settings, optimized_h2o, \n",
    "                                method, basis, cp, \"distorted_h2o\", optimized = True)\n",
    "mbfit.init_database(settings_nh3, database_settings, optimized_nh3, \n",
    "                                method, basis, cp, \"distorted_nh3\", optimized = True)\n",
    "\n",
    "mbfit.fill_database(dim_settings,  database_settings, client_name, \"distorted_h2o\", \"distorted_nh3\")\n",
    "\n",
    "mbfit.generate_training_set(settings_h2o, database_settings, screened_configurations_h2o, \n",
    "                                        method, basis, cp, \"distorted_h2o\", \n",
    "                                        e_bind_max = bind_emax, e_mon_max = mon_emax)\n",
    "\n",
    "mbfit.generate_training_set(settings_nh3, database_settings, screened_configurations_nh3, \n",
    "                                        method, basis, cp, \"distorted_nh3\", \n",
    "                                        e_bind_max = bind_emax, e_mon_max = mon_emax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the distorted monomers we can now call the same function as for the rigid, but using the set of distorted monomers instead of the optimized geommetries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_configs = \"flex_configs_train.xyz\"\n",
    "test_configs = \"flex_configs_test.xyz\"\n",
    "min_d_2b = 1.0\n",
    "max_d_2b = 9.0\n",
    "min_inter_d = 0.5\n",
    "seed_training = 123\n",
    "seed_test = 543\n",
    "bind_emax = 150.0\n",
    "mon_emax = 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "mbfit.generate_2b_configurations(dim_settings, screened_configurations_nh3, screened_configurations_h2o, \n",
    "                                 num_flex_train_configs, training_configs, \n",
    "                                 min_distance = min_d_2b, \n",
    "                                 max_distance = max_d_2b, \n",
    "                                 min_inter_distance = min_inter_d, \n",
    "                                 progression = True, logarithmic = True,\n",
    "                                 seed = seed_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "mbfit.generate_2b_configurations(dim_settings, screened_configurations_nh3, screened_configurations_h2o, \n",
    "                                 num_flex_test_configs, test_configs, \n",
    "                                 min_distance = min_d_2b, \n",
    "                                 max_distance = max_d_2b, \n",
    "                                 min_inter_distance = min_inter_d, \n",
    "                                 progression = True, logarithmic = True,\n",
    "                                 seed = seed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "mbfit.init_database(dim_settings, database_settings, \n",
    "                                training_configs, method, basis, \n",
    "                                cp, \"training_nh3h2omb\", optimized = False)\n",
    "# Test Set\n",
    "mbfit.init_database(dim_settings, database_settings, \n",
    "                                test_configs, method, basis, \n",
    "                                cp, \"test_nh3h2omb\", optimized = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for the normal mode configurations, we first need to optimize a dimer and get its normal modes. the initial gess of the dimer structure can be given by the user, but can also be generated using the `generate_2b_configurations` function by just generating 1 configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unoptimized_dimer = \"dimer.xyz\"\n",
    "optimized_dimer = \"optimized_dimer.xyz\"\n",
    "normal_modes_dimer = \"normal_modes_dimer.dat\"\n",
    "training_configs = \"nm_configs_train.xyz\"\n",
    "test_configs = \"nm_configs_test.xyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_2b_configurations(dim_settings, optimized_nh3, optimized_h2o, \n",
    "                                 1, unoptimized_dimer, \n",
    "                                 min_distance = 3, \n",
    "                                 max_distance = 4, \n",
    "                                 min_inter_distance = min_inter_d, \n",
    "                                 progression = True, logarithmic = False,\n",
    "                                 seed = 1010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.optimize_geometry(dim_settings, unoptimized_dimer, optimized_dimer, method, basis, qchem_qm_options)\n",
    "mbfit.generate_normal_modes(dim_settings, optimized_dimer, normal_modes_dimer, method, basis, qchem_qm_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "mbfit.generate_normal_mode_configurations(dim_settings, optimized_dimer, normal_modes_dimer, \n",
    "                                          training_configs, number_of_configs=num_nm_train_configs, \n",
    "                                          seed=seed_training, classical=classical)\n",
    "# Test\n",
    "mbfit.generate_normal_mode_configurations(dim_settings, optimized_dimer, normal_modes_dimer, \n",
    "                                          test_configs, number_of_configs=num_nm_test_configs, \n",
    "                                          seed=seed_training, classical=classical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "mbfit.init_database(dim_settings, database_settings, \n",
    "                                training_configs, method, basis, \n",
    "                                cp, \"training_nh3h2omb\", optimized = False)\n",
    "# Test Set\n",
    "mbfit.init_database(dim_settings, database_settings, \n",
    "                                test_configs, method, basis, \n",
    "                                cp, \"test_nh3h2omb\", optimized = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the configurations have been added to the database, the calculation and generation of the training and test sets can start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = \"mbnrg_training_set.xyz\"\n",
    "test_set = \"mbnrg_test_set.xyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the database\n",
    "mbfit.fill_database(dim_settings,  database_settings, client_name, \"training_nh3h2omb\", \"test_nh3h2omb\")\n",
    "\n",
    "# Generate training set\n",
    "mbfit.generate_training_set(dim_settings, database_settings, training_set, \n",
    "                                        method, basis, cp, \"training_nh3h2omb\", \n",
    "                                        e_bind_max = bind_emax, e_mon_max = mon_emax)\n",
    "\n",
    "# Generate test set\n",
    "mbfit.generate_training_set(dim_settings, database_settings, test_set, \n",
    "                                        method, basis, cp, \"test_nh3h2omb\", \n",
    "                                        e_bind_max = bind_emax, e_mon_max = mon_emax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Body MB-nrg Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the system properties were already calculated for the TTM-nrg fit, we can move on straight to the MB-nrg fit. The fitting code generation, fit set up, fitting and retrievement of the best fit are performed in the same way as the 1B fit for MB-nrg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimer_fitting_code_dir = \"fitting_code_dimer_mbnrg\"\n",
    "fits_dimer = \"fits_mbnrg_dimer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_mbnrg_fitting_code(dim_settings, config_dimer, poly_in_dim, polynomial_directory_dimer, \n",
    "                                  polynomial_order_dimer, dimer_fitting_code_dir, use_direct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.compile_fit_code(dim_settings,dimer_fitting_code_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for this example we will perform the fit over TTM. However, that is our choice and the fit could just be performed using just the polynomials to describe the repulsion energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.prepare_fits(dim_settings, dimer_fitting_code_dir, training_set,fits_dimer,num_fits = 2, over_ttm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.execute_fits(dim_settings,fits_dimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.retrieve_best_fit(dim_settings,fits_dimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can plot the correlation plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies_training = mbfit.get_correlation_data(dim_settings, dimer_fitting_code_dir, fits_dimer,\n",
    "                                               training_set, split_energy = 10.0, over_ttm = True,\n",
    "                                               min_energy_plot=-10.0, max_energy_plot=30.0,\n",
    "                                               correlation_prefix=\"correlation_2b_nh3h2o_mb_train\",\n",
    "                                              correlation_directory = \"correlation_2b_nh3h2o_mb_train\",\n",
    "                                              minor_tick = 2.5, colors = ['black','darkgreen'],\n",
    "                                              labels = [\"This is the X-axis\", \"And this the Y axis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "energies_test = mbfit.get_correlation_data(dim_settings, dimer_fitting_code_dir, fits_dimer,\n",
    "                                           test_set, split_energy = 10.0, min_energy_plot=-10.0, \n",
    "                                           max_energy_plot=30.0, over_ttm = True,\n",
    "                                               correlation_prefix=\"correlation_2b_nh3h2o_mb_test\",\n",
    "                                              correlation_directory = \"correlation_2b_nh3h2o_mb_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add PEF to MBX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_MBX_files(dim_settings, config_dimer, mon_ids, polynomial_order_dimer, do_ttmnrg = False, \n",
    "                         MBX_HOME = None, version = \"v1\", mbnrg_fits_path=fits_dimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
